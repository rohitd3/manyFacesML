<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Identifying faces | rohitd3’s fastpages</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Identifying faces" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="we identify faces" />
<meta property="og:description" content="we identify faces" />
<link rel="canonical" href="https://rohitd3.github.io/manyFacesML/python/2023/05/16/facesIdentify.html" />
<meta property="og:url" content="https://rohitd3.github.io/manyFacesML/python/2023/05/16/facesIdentify.html" />
<meta property="og:site_name" content="rohitd3’s fastpages" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-05-16T00:00:00-05:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Identifying faces" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-05-16T00:00:00-05:00","datePublished":"2023-05-16T00:00:00-05:00","description":"we identify faces","headline":"Identifying faces","mainEntityOfPage":{"@type":"WebPage","@id":"https://rohitd3.github.io/manyFacesML/python/2023/05/16/facesIdentify.html"},"url":"https://rohitd3.github.io/manyFacesML/python/2023/05/16/facesIdentify.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/manyFacesML/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://rohitd3.github.io/manyFacesML/feed.xml" title="rohitd3's fastpages" /><link rel="shortcut icon" type="image/x-icon" href="/manyFacesML/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/manyFacesML/">rohitd3&#39;s fastpages</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/manyFacesML/about/">About Me</a><a class="page-link" href="/manyFacesML/search/">Search</a><a class="page-link" href="/manyFacesML/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Identifying faces</h1><p class="page-description">we identify faces</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2023-05-16T00:00:00-05:00" itemprop="datePublished">
        May 16, 2023
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      16 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/manyFacesML/categories/#python">python</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-justify-center">
          <div class="px-2">

    <a href="https://github.com/rohitd3/manyFacesML/tree/master/_notebooks/facesIdentify.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/manyFacesML/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/rohitd3/manyFacesML/master?filepath=_notebooks%2FfacesIdentify.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/manyFacesML/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/rohitd3/manyFacesML/blob/master/_notebooks/facesIdentify.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/manyFacesML/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
          <div class="px-2">
  <a href="https://deepnote.com/launch?url=https%3A%2F%2Fgithub.com%2Frohitd3%2FmanyFacesML%2Fblob%2Fmaster%2F_notebooks%2FfacesIdentify.ipynb" target="_blank">
      <img class="notebook-badge-image" src="/manyFacesML/assets/badges/deepnote.svg" alt="Launch in Deepnote"/>
  </a>
</div>

        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/facesIdentify.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">torch</span> <span class="n">torchvision</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">torchviz</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="o">--</span><span class="n">upgrade</span> <span class="n">torch</span> <span class="n">torchvision</span>

<span class="c1"># the Pandas mismatch hasn&#39;t been a problem, because we aren&#39;t using it in our code</span>
<span class="c1">#   ERROR: google-colab 1.0.0 has requirement pandas~=1.0.0; python_version &gt;= &quot;3.0&quot;, but you&#39;ll have pandas 1.1.0 which is incompatible.</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1)
Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2)
Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)
Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)
Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)
Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)
Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)
Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.99)
Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.99)
Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.101)
Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch) (8.5.0.96)
Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch) (11.10.3.66)
Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch) (10.9.0.58)
Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch) (10.2.10.91)
Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.0.1)
Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.4.91)
Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch) (2.14.3)
Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.91)
Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)
Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66-&gt;torch) (67.7.2)
Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66-&gt;torch) (0.40.0)
Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-&gt;torch) (3.25.2)
Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-&gt;torch) (16.0.3)
Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)
Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)
Requirement already satisfied: pillow!=8.3.*,&gt;=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0)
Requirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-&gt;torch) (2.1.2)
Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;torchvision) (1.26.15)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;torchvision) (2022.12.7)
Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;torchvision) (2.0.12)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;torchvision) (3.4)
Requirement already satisfied: mpmath&gt;=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-&gt;torch) (1.3.0)
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Requirement already satisfied: torchviz in /usr/local/lib/python3.10/dist-packages (0.0.2)
Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchviz) (2.0.1)
Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from torchviz) (0.20.1)
Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch-&gt;torchviz) (3.12.0)
Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch-&gt;torchviz) (4.5.0)
Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch-&gt;torchviz) (1.11.1)
Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch-&gt;torchviz) (3.1)
Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;torchviz) (3.1.2)
Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;torchviz) (11.7.99)
Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;torchviz) (11.7.99)
Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;torchviz) (11.7.101)
Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;torchviz) (8.5.0.96)
Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;torchviz) (11.10.3.66)
Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;torchviz) (10.9.0.58)
Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;torchviz) (10.2.10.91)
Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;torchviz) (11.4.0.1)
Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;torchviz) (11.7.4.91)
Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;torchviz) (2.14.3)
Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;torchviz) (11.7.91)
Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;torchviz) (2.0.0)
Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66-&gt;torch-&gt;torchviz) (67.7.2)
Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66-&gt;torch-&gt;torchviz) (0.40.0)
Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-&gt;torch-&gt;torchviz) (3.25.2)
Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-&gt;torch-&gt;torchviz) (16.0.3)
Requirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-&gt;torch-&gt;torchviz) (2.1.2)
Requirement already satisfied: mpmath&gt;=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-&gt;torch-&gt;torchviz) (1.3.0)
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1)
Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2)
Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)
Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)
Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)
Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)
Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)
Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.99)
Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.99)
Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.101)
Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch) (8.5.0.96)
Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch) (11.10.3.66)
Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch) (10.9.0.58)
Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch) (10.2.10.91)
Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.0.1)
Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.4.91)
Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch) (2.14.3)
Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.91)
Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)
Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66-&gt;torch) (67.7.2)
Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66-&gt;torch) (0.40.0)
Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-&gt;torch) (3.25.2)
Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-&gt;torch) (16.0.3)
Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)
Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)
Requirement already satisfied: pillow!=8.3.*,&gt;=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0)
Requirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-&gt;torch) (2.1.2)
Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;torchvision) (1.26.15)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;torchvision) (2022.12.7)
Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;torchvision) (2.0.12)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;torchvision) (3.4)
Requirement already satisfied: mpmath&gt;=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-&gt;torch) (1.3.0)
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>

<span class="k">def</span> <span class="nf">restart_runtime</span><span class="p">():</span>
  <span class="n">os</span><span class="o">.</span><span class="n">kill</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getpid</span><span class="p">(),</span> <span class="mi">9</span><span class="p">)</span>

<span class="n">restart_runtime</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="c1"># Websites for Binary classification on Images</span>
<span class="c1"># https://github.com/jayrodge/Binary-Image-Classifier-PyTorch</span>
<span class="c1"># https://github.com/jayrodge/Binary-Image-Classifier-PyTorch/blob/master/Binary_face_classifier.ipynb</span>
<span class="c1"># https://hackernoon.com/binary-face-classifier-using-pytorch-2d835ccb7816 - this website explains the following code</span>


<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="kn">from</span> <span class="nn">torch.utils.data.sampler</span> <span class="kn">import</span> <span class="n">SubsetRandomSampler</span>


<span class="c1"># import torch.nn as nn</span>
<span class="c1"># import torch.optim as optim</span>
<span class="c1"># import torch.utils.data as data</span>
<span class="c1"># import torchvision.models as models</span>
<span class="c1"># # from torch.autograd import Variable</span>
<span class="c1"># from torchvision.models.vgg import model_urls</span>
<span class="c1"># from torchviz import make_dot</span>

<span class="c1"># The following program is obtained from:</span>
<span class="c1"># https://github.com/jayrodge/Binary-Image-Classifier-PyTorch/blob/master/Binary_face_classifier.ipynb</span>
<span class="c1">#</span>
<span class="c1"># Visualization tool</span>
<span class="c1"># https://stackoverflow.com/questions/52468956/how-do-i-visualize-a-net-in-pytorch </span>



<span class="kn">from</span> <span class="nn">google.colab</span> <span class="kn">import</span> <span class="n">drive</span>
<span class="kn">from</span> <span class="nn">google.colab</span> <span class="kn">import</span> <span class="n">files</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>

<span class="n">drive</span><span class="o">.</span><span class="n">mount</span><span class="p">(</span><span class="s1">&#39;/content/gdrive&#39;</span><span class="p">)</span>

<span class="c1">#########################################################</span>
<span class="c1"># Processing the Dataset</span>
<span class="c1">#-------------------------</span>
<span class="c1"># You might often need to process the image data before passing it to the model.</span>
<span class="c1"># For example, if the sizes of all images are different (which often the case in large datasets), </span>
<span class="c1"># then your model will throw an error. So resize them, and you can consider rescaling the pixel values also.</span>
<span class="c1"># Apart from this, you can perform diverse transforms for data augmentation.</span>
<span class="c1"># An elegant way to apply multiple transforms is using transform.compose() as shown below.</span>
<span class="c1">#</span>
<span class="c1"># When comes to loading/ preprocessing the data PyTorch is much simpler as compared to other libraries. </span>
<span class="c1"># However, PyTorch has a built-in function called transforms using which you can perform all your pre-processing tasks </span>
<span class="c1">##############################################################</span>

<span class="c1"># how many samples per batch to load</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>

<span class="c1"># percentage of training set to use as validation</span>
<span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.3</span> <span class="c1"># test size is 30% of the total images that means training size is 70% of the total images</span>
<span class="n">valid_size</span> <span class="o">=</span> <span class="mf">0.1</span> <span class="c1"># validation is 10% of the training image; validation comes before testing and validates each input</span>


<span class="n">ImageWidth</span><span class="o">=</span><span class="mi">384</span>
<span class="n">ImageHeight</span><span class="o">=</span><span class="mi">384</span>

<span class="c1">#the most common choices for convolution filter kernel sizes appear to be square shape of sizes 3X3, 5X5</span>
<span class="c1">#smaller sized kernel allows for more granular information. Here 5X5 is used.</span>
<span class="c1">#Maxpool is needed when the image is larger. It keeps the item with the maximum value.</span>
<span class="n">convKernelSize1</span> <span class="o">=</span><span class="mi">5</span>
<span class="n">convKernelSize2</span> <span class="o">=</span><span class="mi">5</span>
<span class="n">maxpoolKernelSize</span> <span class="o">=</span> <span class="mi">2</span>

<span class="c1">#conv1 Input Channel is defalut 3 for R, G, B channels directly from the colored Image</span>
<span class="n">convOutputChannel1</span> <span class="o">=</span> <span class="mi">16</span>
<span class="c1">#convInputChannel2 is the same as the convOutputChannel1</span>
<span class="n">convOutputChannel2</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">linearOut1</span> <span class="o">=</span> <span class="mi">256</span>
<span class="n">linearOut2</span> <span class="o">=</span> <span class="mi">84</span>

<span class="n">dropOutValue</span> <span class="o">=</span> <span class="mf">0.2</span>
<span class="c1">#------------------------------------------------------------------------</span>


<span class="c1"># for the first convolution and max pool</span>
<span class="n">height1</span><span class="o">=</span><span class="nb">int</span><span class="p">((</span><span class="n">ImageHeight</span> <span class="o">-</span> <span class="n">convKernelSize1</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="n">maxpoolKernelSize</span><span class="p">)</span> 
<span class="n">width1</span><span class="o">=</span><span class="nb">int</span><span class="p">((</span><span class="n">ImageWidth</span> <span class="o">-</span> <span class="n">convKernelSize1</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="n">maxpoolKernelSize</span><span class="p">)</span>

<span class="c1"># for the second convolution and max pool</span>
<span class="n">height2</span><span class="o">=</span><span class="nb">int</span><span class="p">((</span><span class="n">height1</span> <span class="o">-</span> <span class="n">convKernelSize2</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="n">maxpoolKernelSize</span><span class="p">)</span> 
<span class="n">width2</span><span class="o">=</span><span class="nb">int</span><span class="p">((</span><span class="n">width1</span> <span class="o">-</span> <span class="n">convKernelSize2</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="n">maxpoolKernelSize</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot; ImageWidth = &quot;</span><span class="p">,</span> <span class="n">ImageWidth</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot; ImageHeight = &quot;</span><span class="p">,</span> <span class="n">ImageHeight</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot; width1 = &quot;</span><span class="p">,</span> <span class="n">width1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot; height1 = &quot;</span><span class="p">,</span> <span class="n">height1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot; width2 = &quot;</span><span class="p">,</span> <span class="n">width2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot; height2 = &quot;</span><span class="p">,</span> <span class="n">height2</span><span class="p">)</span>

<span class="n">train_transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">RandomRotation</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">ImageWidth</span><span class="p">,</span><span class="n">ImageHeight</span><span class="p">)),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">))</span> <span class="c1"># need to keep these transforms, at least do resize all images to same size and co</span>
    <span class="p">])</span>

<span class="c1">###########################################################################</span>


<span class="c1">#------------------------------------------------------------------------</span>

<span class="n">data_directory_face</span> <span class="o">=</span> <span class="s1">&#39;/content/gdrive/MyDrive/DNN_ML/face&#39;</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2"> ****************  START LOADING DATA AND PROCESSING ******************* &quot;</span><span class="p">)</span>

<span class="c1">###########</span>
<span class="c1"># Select one of the above data_directory_XYZ</span>
<span class="c1"># Depending on what you want to run. </span>
<span class="c1"># You can change this part for different tests</span>
<span class="c1">############</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">ImageFolder</span><span class="p">(</span><span class="n">data_directory_face</span><span class="p">,</span><span class="n">transform</span><span class="o">=</span><span class="n">train_transform</span><span class="p">)</span> 
<span class="c1"># data = datasets.ImageFolder(data_directory_tumor)</span>

<span class="c1"># The data needs to be split in Train, Test and validation set before training.</span>
<span class="c1"># - Train set will be used to train the model.</span>
<span class="c1"># - Validation set will be used for validating the model after each epoch. </span>
<span class="c1"># - Test set will be used to evaluate the model once it is trained.</span>


<span class="n">num_data</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;num_data = &quot;</span><span class="p">,</span> <span class="n">num_data</span><span class="p">)</span>

<span class="n">indices_data</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">num_data</span><span class="p">))</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">indices_data</span><span class="p">)</span>

<span class="c1">#For test and training</span>
<span class="c1">#------------------------------</span>
<span class="n">split_tt</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">test_size</span> <span class="o">*</span> <span class="n">num_data</span><span class="p">))</span>
<span class="n">train_idx</span><span class="p">,</span> <span class="n">test_idx</span> <span class="o">=</span> <span class="n">indices_data</span><span class="p">[</span><span class="n">split_tt</span><span class="p">:],</span> <span class="n">indices_data</span><span class="p">[:</span><span class="n">split_tt</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> train_idx = &quot;</span><span class="p">,</span> <span class="n">train_idx</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> test_idx = &quot;</span><span class="p">,</span> <span class="n">test_idx</span><span class="p">)</span>

<span class="c1">#From Training separate something For validation (for each epoch)</span>
<span class="c1">#---------------------------------------------------------------</span>
<span class="n">num_train</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_idx</span><span class="p">)</span>
<span class="n">indices_train</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">num_train</span><span class="p">))</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">indices_train</span><span class="p">)</span>
<span class="n">split_tv</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">valid_size</span> <span class="o">*</span> <span class="n">num_train</span><span class="p">))</span>
<span class="n">train_new_idx</span><span class="p">,</span> <span class="n">valid_idx</span> <span class="o">=</span> <span class="n">indices_train</span><span class="p">[</span><span class="n">split_tv</span><span class="p">:],</span><span class="n">indices_train</span><span class="p">[:</span><span class="n">split_tv</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2"> train_new_idx = &quot;</span><span class="p">,</span> <span class="n">train_new_idx</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> valid_idx = &quot;</span><span class="p">,</span> <span class="n">valid_idx</span><span class="p">)</span>

<span class="c1"># define samplers for obtaining training and validation batches</span>
<span class="n">train_sampler</span> <span class="o">=</span> <span class="n">SubsetRandomSampler</span><span class="p">(</span><span class="n">train_new_idx</span><span class="p">)</span>
<span class="n">valid_sampler</span> <span class="o">=</span> <span class="n">SubsetRandomSampler</span><span class="p">(</span><span class="n">valid_idx</span><span class="p">)</span>
<span class="n">test_sampler</span> <span class="o">=</span> <span class="n">SubsetRandomSampler</span><span class="p">(</span><span class="n">test_idx</span><span class="p">)</span>



<span class="c1"># Loaders contains the data in tuple format (Image in form of tensor, label)</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="n">train_sampler</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># only running the data augmentation on the training data, double check if works</span>
<span class="n">valid_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="n">valid_sampler</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">sampler</span> <span class="o">=</span> <span class="n">test_sampler</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># variable representing classes of the images</span>
<span class="n">classes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># labeling either 0 (negative) or 1 (positive)</span>

<span class="n">total_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_loader</span><span class="p">)</span><span class="o">*</span><span class="n">batch_size</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">valid_loader</span><span class="p">)</span><span class="o">*</span><span class="n">batch_size</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span><span class="o">*</span><span class="n">batch_size</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;total_length = &quot;</span><span class="p">,</span> <span class="n">total_length</span><span class="p">)</span>

<span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">valid_loader</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;batch[0].size() = &quot;</span><span class="p">,</span> <span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>


<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>

<span class="c1"># helper function to un-normalize and display an image</span>
<span class="k">def</span> <span class="nf">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">):</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">img</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">+</span> <span class="mf">0.5</span>  <span class="c1"># unnormalize</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)))</span>  <span class="c1"># convert from Tensor image</span>
    
<span class="c1"># obtain one batch of training images</span>
<span class="n">dataiter</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>
<span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">dataiter</span><span class="p">)</span>
<span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="c1"># convert images to numpy for display</span>

<span class="c1"># plot the images in the batch, along with the corresponding labels</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot; ------------------ display images ------------------------&quot;</span><span class="p">)</span>
<span class="c1"># display some images with Labels to see if labeling appears correct</span>


<span class="n">no_of_image_to_display</span> <span class="o">=</span> <span class="mi">10</span>
<span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">no_of_image_to_display</span><span class="p">):</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">no_of_image_to_display</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">idx</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">xticks</span><span class="o">=</span><span class="p">[],</span> <span class="n">yticks</span><span class="o">=</span><span class="p">[])</span>
    <span class="n">imshow</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">classes</span><span class="p">[</span><span class="n">labels</span><span class="p">[</span><span class="n">idx</span><span class="p">]])</span>

<span class="n">display</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">())</span>
<span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>



<span class="c1"># Building the Model: Decrypting the layers</span>
<span class="c1"># ---------------------------------------------</span>
<span class="c1"># The model class definition should always have __init__() method. In this, we will initialize the blocks/layers and other parameters.</span>
<span class="c1"># Talking about the neural network layers, there are 3 main types in image classification: convolutional, max pooling, and dropout .</span>

<span class="c1"># Convolution layers:  Convolutional layers will extract features from the input image and generate feature maps/activations. </span>
<span class="c1"># You can decide how many activations you want using the filters argument. </span>
<span class="c1"># Basically, when you apply convolution upon an image, the kernel will pass over the entire image in small parts, </span>
<span class="c1"># and it will give an activation. It is demonstrated in the below image.</span>

<span class="c1"># Pooling Layers</span>
<span class="c1"># When we use conv2d layers, we end up with a lot of feature maps that occupy high computational space. </span>
<span class="c1"># In order to decrease the computational time and space required, you can use Max pooling or average pooling.</span>
<span class="c1"># For each patch/group of the map, only the maximum is chosen to form the output. </span>
<span class="c1"># The below image clearly demonstrates the work.</span>

<span class="c1"># Dropout Layers</span>
<span class="c1"># You can guess its function from the name itself! It drops out like 10-20% of the data.</span>
<span class="c1"># Overfitting is a common problem when you are training over the same data for many iterations/epochs. </span>
<span class="c1"># By dropping out a randomly chosen 10% of data, the model will be able to generalize more to new data.</span>
<span class="c1"># This concludes with a brief description of the layers we have used in our code. </span>
<span class="c1"># Note that the final layer has output as 2, as it is binary classification.</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Mounted at /content/gdrive
 ImageWidth =  384
 ImageHeight =  384
 width1 =  190
 height1 =  190
 width2 =  93
 height2 =  93


 ****************  START LOADING DATA AND PROCESSING ******************* 
num_data =  400

 train_idx =  [233, 261, 54, 14, 246, 47, 309, 360, 215, 189, 131, 22, 252, 25, 186, 164, 66, 253, 351, 84, 33, 280, 155, 334, 133, 137, 239, 90, 3, 288, 219, 106, 160, 234, 313, 210, 172, 220, 74, 180, 173, 248, 391, 389, 8, 35, 70, 62, 130, 369, 39, 107, 328, 376, 48, 96, 310, 312, 316, 78, 322, 135, 16, 81, 147, 355, 341, 191, 365, 42, 257, 188, 176, 283, 317, 128, 352, 153, 41, 353, 386, 15, 304, 17, 20, 179, 2, 238, 320, 91, 292, 77, 113, 354, 331, 291, 300, 27, 101, 152, 4, 229, 80, 242, 230, 86, 209, 255, 357, 208, 34, 75, 104, 5, 375, 216, 293, 221, 166, 398, 139, 149, 314, 59, 199, 350, 387, 228, 323, 125, 298, 315, 264, 67, 60, 397, 26, 218, 142, 19, 124, 192, 185, 243, 311, 196, 79, 49, 203, 279, 61, 36, 69, 336, 284, 390, 281, 115, 269, 213, 295, 324, 382, 6, 117, 92, 294, 207, 163, 184, 103, 335, 177, 272, 301, 394, 342, 169, 162, 287, 87, 57, 373, 235, 114, 205, 399, 332, 64, 23, 273, 379, 225, 378, 119, 136, 296, 111, 381, 345, 277, 259, 359, 201, 10, 156, 374, 231, 105, 222, 145, 250, 108, 262, 385, 43, 141, 299, 362, 232, 58, 282, 223, 195, 285, 366, 327, 170, 290, 138, 356, 198, 50, 11, 71, 349, 206, 120, 346, 110, 347, 40, 319, 175, 21, 7, 102, 97, 364, 276, 384, 396, 181, 63, 28, 241, 202, 126, 340, 159, 174, 275, 65, 371, 370, 143, 271, 268, 167, 116, 100, 89, 140, 270, 393, 144, 306, 289, 150, 154]

 test_idx =  [348, 254, 227, 157, 182, 333, 380, 122, 112, 392, 226, 51, 367, 183, 123, 88, 190, 95, 224, 338, 9, 158, 18, 286, 32, 329, 83, 344, 358, 53, 240, 134, 302, 129, 330, 194, 161, 297, 343, 118, 98, 260, 388, 266, 267, 395, 72, 1, 321, 307, 168, 217, 204, 37, 171, 361, 0, 132, 31, 372, 56, 38, 187, 325, 237, 45, 82, 308, 263, 200, 383, 256, 165, 148, 24, 52, 377, 93, 278, 245, 251, 337, 193, 44, 121, 244, 363, 247, 30, 178, 339, 13, 236, 214, 368, 127, 151, 29, 73, 109, 68, 55, 211, 318, 12, 303, 197, 85, 46, 212, 258, 249, 305, 146, 76, 99, 326, 265, 274, 94]


 train_new_idx =  [153, 273, 144, 269, 161, 133, 192, 157, 234, 176, 6, 135, 139, 238, 250, 145, 103, 60, 93, 81, 201, 245, 167, 179, 98, 12, 27, 212, 187, 10, 15, 247, 279, 87, 76, 166, 119, 11, 183, 136, 97, 209, 233, 262, 159, 20, 18, 211, 46, 265, 0, 170, 8, 106, 68, 78, 89, 21, 240, 210, 216, 160, 235, 17, 271, 24, 107, 130, 116, 129, 71, 147, 101, 77, 83, 5, 100, 67, 19, 158, 172, 174, 203, 40, 168, 274, 104, 64, 70, 189, 91, 127, 50, 109, 88, 94, 110, 222, 123, 193, 3, 39, 215, 128, 33, 186, 23, 82, 246, 267, 72, 36, 231, 65, 131, 154, 241, 126, 224, 53, 169, 52, 257, 253, 206, 199, 28, 227, 84, 30, 114, 146, 155, 223, 45, 277, 248, 251, 74, 25, 184, 204, 200, 134, 85, 228, 111, 177, 117, 56, 16, 57, 278, 181, 102, 188, 132, 175, 140, 141, 202, 152, 59, 171, 205, 143, 190, 62, 263, 122, 258, 226, 105, 148, 198, 239, 49, 92, 137, 1, 260, 9, 236, 47, 69, 138, 261, 54, 120, 58, 26, 173, 112, 219, 197, 156, 51, 191, 259, 254, 182, 4, 142, 194, 124, 151, 32, 229, 268, 66, 115, 118, 255, 178, 163, 75, 270, 37, 2, 213, 249, 35, 272, 275, 242, 80, 149, 38, 208, 232, 90, 22, 243, 63, 99, 225, 14, 43, 44, 196, 218, 162, 214, 256, 180, 195, 48, 164, 237, 31, 230, 217]

 valid_idx =  [276, 95, 79, 7, 29, 165, 221, 150, 266, 73, 34, 86, 13, 264, 220, 244, 55, 185, 252, 113, 96, 207, 41, 125, 42, 61, 121, 108]
total_length =  416
batch[0].size() =  torch.Size([16, 3, 384, 384])
batch[0].size() =  torch.Size([12, 3, 384, 384])
 ------------------ display images ------------------------
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">ValueError</span>                                Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-1-93c234046ca2&gt;</span> in <span class="ansi-cyan-fg">&lt;cell line: 195&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">    194</span> no_of_image_to_display <span class="ansi-blue-fg">=</span> <span class="ansi-cyan-fg">10</span>
<span class="ansi-green-intense-fg ansi-bold">    195</span> <span class="ansi-green-fg">for</span> idx <span class="ansi-green-fg">in</span> np<span class="ansi-blue-fg">.</span>arange<span class="ansi-blue-fg">(</span>no_of_image_to_display<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 196</span><span class="ansi-red-fg">     </span>ax <span class="ansi-blue-fg">=</span> fig<span class="ansi-blue-fg">.</span>add_subplot<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">2</span><span class="ansi-blue-fg">,</span> no_of_image_to_display<span class="ansi-blue-fg">/</span><span class="ansi-cyan-fg">2</span><span class="ansi-blue-fg">,</span> idx<span class="ansi-blue-fg">+</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">,</span> xticks<span class="ansi-blue-fg">=</span><span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">,</span> yticks<span class="ansi-blue-fg">=</span><span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    197</span>     imshow<span class="ansi-blue-fg">(</span>images<span class="ansi-blue-fg">[</span>idx<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    198</span>     ax<span class="ansi-blue-fg">.</span>set_title<span class="ansi-blue-fg">(</span>classes<span class="ansi-blue-fg">[</span>labels<span class="ansi-blue-fg">[</span>idx<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/usr/local/lib/python3.10/dist-packages/matplotlib/figure.py</span> in <span class="ansi-cyan-fg">add_subplot</span><span class="ansi-blue-fg">(self, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    755</span>             projection_class, pkw = self._process_projection_requirements(
<span class="ansi-green-intense-fg ansi-bold">    756</span>                 *args, **kwargs)
<span class="ansi-green-fg">--&gt; 757</span><span class="ansi-red-fg">             </span>ax <span class="ansi-blue-fg">=</span> projection_class<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>pkw<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    758</span>             key <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">(</span>projection_class<span class="ansi-blue-fg">,</span> pkw<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    759</span>         <span class="ansi-green-fg">return</span> self<span class="ansi-blue-fg">.</span>_add_axes_internal<span class="ansi-blue-fg">(</span>ax<span class="ansi-blue-fg">,</span> key<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py</span> in <span class="ansi-cyan-fg">__init__</span><span class="ansi-blue-fg">(self, fig, facecolor, frameon, sharex, sharey, label, xscale, yscale, box_aspect, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    642</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    643</span>             self<span class="ansi-blue-fg">.</span>_position <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_originalPosition <span class="ansi-blue-fg">=</span> mtransforms<span class="ansi-blue-fg">.</span>Bbox<span class="ansi-blue-fg">.</span>unit<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 644</span><span class="ansi-red-fg">             </span>subplotspec <span class="ansi-blue-fg">=</span> SubplotSpec<span class="ansi-blue-fg">.</span>_from_subplot_args<span class="ansi-blue-fg">(</span>fig<span class="ansi-blue-fg">,</span> args<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    645</span>         <span class="ansi-green-fg">if</span> self<span class="ansi-blue-fg">.</span>_position<span class="ansi-blue-fg">.</span>width <span class="ansi-blue-fg">&lt;</span> <span class="ansi-cyan-fg">0</span> <span class="ansi-green-fg">or</span> self<span class="ansi-blue-fg">.</span>_position<span class="ansi-blue-fg">.</span>height <span class="ansi-blue-fg">&lt;</span> <span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    646</span>             <span class="ansi-green-fg">raise</span> ValueError<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#39;Width and height specified must be non-negative&#39;</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/usr/local/lib/python3.10/dist-packages/matplotlib/gridspec.py</span> in <span class="ansi-cyan-fg">_from_subplot_args</span><span class="ansi-blue-fg">(figure, args)</span>
<span class="ansi-green-intense-fg ansi-bold">    585</span>             <span class="ansi-green-fg">raise</span> _api<span class="ansi-blue-fg">.</span>nargs_error<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#34;subplot&#34;</span><span class="ansi-blue-fg">,</span> takes<span class="ansi-blue-fg">=</span><span class="ansi-blue-fg">&#34;1 or 3&#34;</span><span class="ansi-blue-fg">,</span> given<span class="ansi-blue-fg">=</span>len<span class="ansi-blue-fg">(</span>args<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    586</span> 
<span class="ansi-green-fg">--&gt; 587</span><span class="ansi-red-fg">         </span>gs <span class="ansi-blue-fg">=</span> GridSpec<span class="ansi-blue-fg">.</span>_check_gridspec_exists<span class="ansi-blue-fg">(</span>figure<span class="ansi-blue-fg">,</span> rows<span class="ansi-blue-fg">,</span> cols<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    588</span>         <span class="ansi-green-fg">if</span> gs <span class="ansi-green-fg">is</span> <span class="ansi-green-fg">None</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    589</span>             gs <span class="ansi-blue-fg">=</span> GridSpec<span class="ansi-blue-fg">(</span>rows<span class="ansi-blue-fg">,</span> cols<span class="ansi-blue-fg">,</span> figure<span class="ansi-blue-fg">=</span>figure<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/usr/local/lib/python3.10/dist-packages/matplotlib/gridspec.py</span> in <span class="ansi-cyan-fg">_check_gridspec_exists</span><span class="ansi-blue-fg">(figure, nrows, ncols)</span>
<span class="ansi-green-intense-fg ansi-bold">    224</span>                     <span class="ansi-green-fg">return</span> gs
<span class="ansi-green-intense-fg ansi-bold">    225</span>         <span class="ansi-red-fg"># else gridspec not found:</span>
<span class="ansi-green-fg">--&gt; 226</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">return</span> GridSpec<span class="ansi-blue-fg">(</span>nrows<span class="ansi-blue-fg">,</span> ncols<span class="ansi-blue-fg">,</span> figure<span class="ansi-blue-fg">=</span>figure<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    227</span> 
<span class="ansi-green-intense-fg ansi-bold">    228</span>     <span class="ansi-green-fg">def</span> __getitem__<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> key<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">/usr/local/lib/python3.10/dist-packages/matplotlib/gridspec.py</span> in <span class="ansi-cyan-fg">__init__</span><span class="ansi-blue-fg">(self, nrows, ncols, figure, left, bottom, right, top, wspace, hspace, width_ratios, height_ratios)</span>
<span class="ansi-green-intense-fg ansi-bold">    377</span>         self<span class="ansi-blue-fg">.</span>figure <span class="ansi-blue-fg">=</span> figure
<span class="ansi-green-intense-fg ansi-bold">    378</span> 
<span class="ansi-green-fg">--&gt; 379</span><span class="ansi-red-fg">         super().__init__(nrows, ncols,
</span><span class="ansi-green-intense-fg ansi-bold">    380</span>                          width_ratios<span class="ansi-blue-fg">=</span>width_ratios<span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    381</span>                          height_ratios=height_ratios)

<span class="ansi-green-fg">/usr/local/lib/python3.10/dist-packages/matplotlib/gridspec.py</span> in <span class="ansi-cyan-fg">__init__</span><span class="ansi-blue-fg">(self, nrows, ncols, height_ratios, width_ratios)</span>
<span class="ansi-green-intense-fg ansi-bold">     50</span>                 f&#34;Number of rows must be a positive integer, not {nrows!r}&#34;)
<span class="ansi-green-intense-fg ansi-bold">     51</span>         <span class="ansi-green-fg">if</span> <span class="ansi-green-fg">not</span> isinstance<span class="ansi-blue-fg">(</span>ncols<span class="ansi-blue-fg">,</span> Integral<span class="ansi-blue-fg">)</span> <span class="ansi-green-fg">or</span> ncols <span class="ansi-blue-fg">&lt;=</span> <span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">---&gt; 52</span><span class="ansi-red-fg">             raise ValueError(
</span><span class="ansi-green-intense-fg ansi-bold">     53</span>                 f&#34;Number of columns must be a positive integer, not {ncols!r}&#34;)
<span class="ansi-green-intense-fg ansi-bold">     54</span>         self<span class="ansi-blue-fg">.</span>_nrows<span class="ansi-blue-fg">,</span> self<span class="ansi-blue-fg">.</span>_ncols <span class="ansi-blue-fg">=</span> nrows<span class="ansi-blue-fg">,</span> ncols

<span class="ansi-red-fg">ValueError</span>: Number of columns must be a positive integer, not 5.0</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea ">
<pre>&lt;Figure size 1000x400 with 0 Axes&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="rohitd3/manyFacesML"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/manyFacesML/python/2023/05/16/facesIdentify.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/manyFacesML/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="https://rohitd3.github.io/manyFacesML/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/manyFacesML/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Fastpages</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li>
  <a rel="me" href="https://github.com/nighthawkcoders" target="_blank" title="github">
    <svg class="svg-icon grey">
      <use xlink:href="/manyFacesML/assets/minima-social-icons.svg#github"></use>
    </svg>
  </a>
</li>
<li>
  <a rel="me" href="https://twitter.com/NighthawkCoding" target="_blank" title="twitter">
    <svg class="svg-icon grey">
      <use xlink:href="/manyFacesML/assets/minima-social-icons.svg#twitter"></use>
    </svg>
  </a>
</li>
<li>
  <a rel="me" href="https://www.youtube.com/channel/UClIKOsDS5dsfzFA3zveDT3Q" target="_blank" title="youtube">
    <svg class="svg-icon grey">
      <use xlink:href="/manyFacesML/assets/minima-social-icons.svg#youtube"></use>
    </svg>
  </a>
</li>
</ul>
</div>

  </div>

</footer>
</body>

</html>

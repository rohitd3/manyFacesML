{
  
    
        "post0": {
            "title": "What is Pytorch?",
            "content": "Pytorch is an extension of Python that is primarily used for developing machine learning frameworks and deep learning models. The Python syntax is mainly used to code. Pytorch integrates with CUDA that allows it to run well on GPUs. With GPU acceleration, Tensor computing(Like NumPy) is viable on Pytorch. Pytorch is used on various high level software, such as Tesla Autopilot, and Uber Pyro for starters. . Our Project . Our project is a surface level of Pytorch demonstration, and we intend to use it for our own learning purposes as well as yours. As you look through our code, we will try to supplement each segment with supporting blogs to explain as much as we can. .",
            "url": "https://rohitd3.github.io/manyFacesML/2023/06/04/PyTorch.html",
            "relUrl": "/2023/06/04/PyTorch.html",
            "date": " • Jun 4, 2023"
        }
        
    
  
    
        ,"post1": {
            "title": "Accuracy with Pytorch testing",
            "content": ". import torch import torchvision import torchvision.transforms as transforms . ImageWidth = 32 ImageHeight = 32 transform = transforms.Compose([ transforms.RandomHorizontalFlip(), transforms.RandomRotation(60), transforms.Resize((ImageWidth, ImageHeight)), # Modify resize to match the model&#39;s input size transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) ]) . Tensors are the primary data structure used to represent and manipulate data. A tensor is a multi-dimensional array, similar to a matrix. Tensors are efficient for numerical computations and can be easily processed on GPUs, which accelerates the training process. . Images are typically represented as pixel values in a matrix-like format, where each pixel has intensity values for different color channels (e.g., red, green, and blue). To feed images into a CNN model for training or inference, we need to convert them into tensors. . transforms.ToTensor() converts the input image, which is usually in the form of a NumPy array or PIL Image object, into a tensor representation. This tensor representation maintains the spatial dimensions of the image and stores the pixel values as numerical values in the tensor. . We can further apply GPU acceleration. . Converting the image to a tensor allows us to efficiently process and manipulate the image data within the deep learning framework, making it compatible with the operations and computations performed by the CNN model. . trainset = torchvision.datasets.CIFAR10(root=&#39;./data&#39;, train=True, download=True, transform=transform) trainloader = torch.utils.data.DataLoader(trainset, batch_size=8, shuffle=True, num_workers=2) testset = torchvision.datasets.CIFAR10(root=&#39;./data&#39;, train=False, download=True, transform=transform) testloader = torch.utils.data.DataLoader(testset, batch_size=8, shuffle=False, num_workers=2) classes = (&#39;airplane&#39;, &#39;automobile&#39;, &#39;bird&#39;, &#39;cat&#39;, &#39;deer&#39;, &#39;dog&#39;, &#39;frog&#39;, &#39;horse&#39;, &#39;ship&#39;, &#39;truck&#39;) . Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz . 100%|██████████| 170498071/170498071 [00:02&lt;00:00, 77942187.69it/s] . Extracting ./data/cifar-10-python.tar.gz to ./data Files already downloaded and verified . import matplotlib.pyplot as plt import numpy as np # helper function to un-normalize and display an image def imshow(img): img = img / 2 + 0.5 # unnormalize npimg = img.numpy() plt.imshow(np.transpose(npimg, (1, 2, 0))) # convert from Tensor image plt.show() # training images dataiter = iter(trainloader) images, labels = next(dataiter) # show images imshow(torchvision.utils.make_grid(images)) print(&#39;GroundTruth:&#39;, &#39; &#39;.join(&#39;%5s&#39; % classes[labels[j].tolist()] for j in range(min(8, len(labels))))) . GroundTruth: deer bird cat dog automobile frog cat bird . import torch.nn as nn import torch.nn.functional as F # train_on_gpu = torch.cuda.is_available() # print(&quot;train_on_gpu = &quot;, train_on_gpu) class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.conv1 = nn.Conv2d(3, 6, 5) self.pool = nn.MaxPool2d(2, 2) self.conv2 = nn.Conv2d(6, 16, 5) self.fc1 = nn.Linear(16 * 5 * 5, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, x): x = self.pool(F.relu(self.conv1(x))) x = self.pool(F.relu(self.conv2(x))) x = x.view(-1, 16 * 5 * 5) x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x net = Net() . What is ReLu? . ReLU is a special function used in machine learning, specifically in Convolutional Neural Networks (CNNs). It helps the network understand and process information from images or other types of data. . Imagine you have a picture, and you want the computer to analyze it and find important features. ReLU is like a filter that only lets through the important parts and removes the unimportant parts. . ReLU is like a gate that only allows important information to pass through and blocks the rest. By using this function, CNNs can understand and recognize patterns in images, which is useful for tasks like object detection or image classification. . What is Convolution (Conv)? . Imagine you have a picture, and you want the computer to understand different patterns and features in that picture. Convolution is like a window or filter that slides over the image, looking at small portions at a time. It calculates the numerical values based on the pixel values it covers. This operation helps the network identify important patterns, edges, and textures in the image. By applying multiple convolutions with different filters, the network learns to recognize various features in the data. . What is Pooling (Pool)? . After applying convolutions, the network might have extracted a lot of information, including some redundant or less significant details. Pooling helps reduce the amount of information while preserving the important features. It divides the image into small regions and selects the most significant value (e.g., the maximum value, known as max pooling) or calculates an average value (known as average pooling) within each region. This downsampling operation simplifies the representation of the data and makes the network more efficient by reducing the number of parameters it needs to learn. . import torch.optim as optim criterion = nn.CrossEntropyLoss() optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) . Failed to start the Kernel. Kernel Python 3.11.1 is not usable. Check the Jupyter output tab for more information. View Jupyter &lt;a href=&#39;command:jupyter.viewOutput&#39;&gt;log&lt;/a&gt; for further details. . for epoch in range(5): running_loss = 0.0 for i, data in enumerate(trainloader, 0): inputs, labels = data optimizer.zero_grad() outputs = net(inputs) loss = criterion(outputs, labels) loss.backward() optimizer.step() running_loss += loss.item() if i % 2000 == 1999: print(&#39;[%d, %5d] loss: %.3f&#39; % (epoch + 1, i + 1, running_loss / 2000)) running_loss = 0.0 print(&#39;Finished Training&#39;) . [1, 2000] loss: 2.188 [1, 4000] loss: 1.919 [1, 6000] loss: 1.755 [2, 2000] loss: 1.703 [2, 4000] loss: 1.652 [2, 6000] loss: 1.613 [3, 2000] loss: 1.580 [3, 4000] loss: 1.555 [3, 6000] loss: 1.532 [4, 2000] loss: 1.509 [4, 4000] loss: 1.500 [4, 6000] loss: 1.489 [5, 2000] loss: 1.465 [5, 4000] loss: 1.463 [5, 6000] loss: 1.442 Finished Training . What is loss? . The loss value is a metric that quantifies the difference between the predicted outputs of the model and the true labels of the training data. The loss value indicates how well the model is currently performing in terms of its ability to make accurate predictions. . During the training process, the goal is to minimize the loss function. The loss function is a mathematical function that calculates the error between the predicted outputs and the true labels. It provides a measure of how far off the model&#39;s predictions are from the desired outcomes. By iteratively adjusting the model&#39;s parameters using techniques like gradient descent, the loss value is reduced, leading to better predictions. . What is an optimizer? . In machine learning, an optimizer is an algorithm or method that is used to adjust the parameters of a model, such as the weights and biases in a Convolutional Neural Network (CNN), during the training process. The optimizer optimizes or updates the model&#39;s parameters based on the computed gradients of the loss function with respect to those parameters. . The goal of an optimizer is to find the optimal set of parameter values that minimize the loss function, effectively improving the model&#39;s performance. It achieves this by iteratively adjusting the parameters in a way that gradually reduces the loss value. . PATH = &#39;./cifar_net.pth&#39; torch.save(net.state_dict(), PATH) dataiter = iter(testloader) images, labels = next(dataiter) # print images imshow(torchvision.utils.make_grid(images)) print(&quot;Number of labels:&quot;, len(labels)) print(&quot;Labels tuple:&quot;, labels) labels = labels % 7 print(&#39;GroundTruth: &#39;, &#39; &#39;.join(&#39;%5s&#39; % classes[labels[j]] for j in range(min(8, len(labels))))) . Number of labels: 8 Labels tuple: tensor([3, 8, 8, 0, 6, 6, 1, 6]) GroundTruth: cat automobile automobile airplane frog frog automobile frog . outputs = net(images) _, predicted = torch.max(outputs, 1) print(&#39;Predicted: &#39;, &#39; &#39;.join(&#39;%5s&#39; % classes[predicted[j].item()] for j in range(len(predicted)))) print(&#39;Predicted Tensor:&#39;, predicted) print(&#39;Length of Predicted Tensor:&#39;, len(predicted)) . Predicted: cat ship ship airplane deer frog automobile frog Predicted Tensor: tensor([3, 8, 8, 0, 4, 6, 1, 6]) Length of Predicted Tensor: 8 . correct = 0 total = 0 with torch.no_grad(): for data in testloader: images, labels = data outputs = net(images) _, predicted = torch.max(outputs.data, 1) total += labels.size(0) correct += (predicted == labels).sum().item() print(&#39;Accuracy of the network on the 10000 test images: %d %%&#39; % ( 100 * correct / total)) . Accuracy of the network on the 10000 test images: 47 % . class_correct = list(0. for i in range(10)) class_total = list(0. for i in range(10)) with torch.no_grad(): for data in testloader: images, labels = data outputs = net(images) _, predicted = torch.max(outputs, 1) c = (predicted == labels).squeeze() for i in range(4): label = labels[i] class_correct[label] += c[i].item() class_total[label] += 1 for i in range(len(classes)): print(&#39;Accuracy of %5s : %2d %%&#39; % ( classes[i], 100 * class_correct[i] / class_total[i])) . Accuracy of airplane : 48 % Accuracy of automobile : 53 % Accuracy of bird : 45 % Accuracy of cat : 41 % Accuracy of deer : 36 % Accuracy of dog : 46 % Accuracy of frog : 56 % Accuracy of horse : 45 % Accuracy of ship : 68 % Accuracy of truck : 54 % .",
            "url": "https://rohitd3.github.io/manyFacesML/2023/06/04/CNN_usingPytorch.html",
            "relUrl": "/2023/06/04/CNN_usingPytorch.html",
            "date": " • Jun 4, 2023"
        }
        
    
  
    
        ,"post2": {
            "title": "Various categories Pytorch",
            "content": ". import torch import torchvision import torchvision.transforms as transforms . ImageWidth = 32 ImageHeight = 32 transform = transforms.Compose([ transforms.RandomHorizontalFlip(), transforms.RandomRotation(60), transforms.Resize((ImageWidth, ImageHeight)), # Modify resize to match the model&#39;s input size transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) ]) . Tensors are the primary data structure used to represent and manipulate data. A tensor is a multi-dimensional array, similar to a matrix. Tensors are efficient for numerical computations and can be easily processed on GPUs, which accelerates the training process. . Images are typically represented as pixel values in a matrix-like format, where each pixel has intensity values for different color channels (e.g., red, green, and blue). To feed images into a CNN model for training or inference, we need to convert them into tensors. . transforms.ToTensor() converts the input image, which is usually in the form of a NumPy array or PIL Image object, into a tensor representation. This tensor representation maintains the spatial dimensions of the image and stores the pixel values as numerical values in the tensor. . We can further apply GPU acceleration. . Converting the image to a tensor allows us to efficiently process and manipulate the image data within the deep learning framework, making it compatible with the operations and computations performed by the CNN model. . trainset = torchvision.datasets.CIFAR10(root=&#39;./data&#39;, train=True, download=True, transform=transform) trainloader = torch.utils.data.DataLoader(trainset, batch_size=8, shuffle=True, num_workers=2) testset = torchvision.datasets.CIFAR10(root=&#39;./data&#39;, train=False, download=True, transform=transform) testloader = torch.utils.data.DataLoader(testset, batch_size=8, shuffle=False, num_workers=2) classes = (&#39;airplane&#39;, &#39;automobile&#39;, &#39;bird&#39;, &#39;cat&#39;, &#39;deer&#39;, &#39;dog&#39;, &#39;frog&#39;, &#39;horse&#39;, &#39;ship&#39;, &#39;truck&#39;) . Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz . 100%|██████████| 170498071/170498071 [00:02&lt;00:00, 77942187.69it/s] . Extracting ./data/cifar-10-python.tar.gz to ./data Files already downloaded and verified . import matplotlib.pyplot as plt import numpy as np # helper function to un-normalize and display an image def imshow(img): img = img / 2 + 0.5 # unnormalize npimg = img.numpy() plt.imshow(np.transpose(npimg, (1, 2, 0))) # convert from Tensor image plt.show() # training images dataiter = iter(trainloader) images, labels = next(dataiter) # show images imshow(torchvision.utils.make_grid(images)) print(&#39;GroundTruth:&#39;, &#39; &#39;.join(&#39;%5s&#39; % classes[labels[j].tolist()] for j in range(min(8, len(labels))))) . GroundTruth: deer bird cat dog automobile frog cat bird . import torch.nn as nn import torch.nn.functional as F # train_on_gpu = torch.cuda.is_available() # print(&quot;train_on_gpu = &quot;, train_on_gpu) class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.conv1 = nn.Conv2d(3, 6, 5) self.pool = nn.MaxPool2d(2, 2) self.conv2 = nn.Conv2d(6, 16, 5) self.fc1 = nn.Linear(16 * 5 * 5, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, x): x = self.pool(F.relu(self.conv1(x))) x = self.pool(F.relu(self.conv2(x))) x = x.view(-1, 16 * 5 * 5) x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x net = Net() . What is ReLu? . ReLU is a special function used in machine learning, specifically in Convolutional Neural Networks (CNNs). It helps the network understand and process information from images or other types of data. . Imagine you have a picture, and you want the computer to analyze it and find important features. ReLU is like a filter that only lets through the important parts and removes the unimportant parts. . ReLU is like a gate that only allows important information to pass through and blocks the rest. By using this function, CNNs can understand and recognize patterns in images, which is useful for tasks like object detection or image classification. . What is Convolution (Conv)? . Imagine you have a picture, and you want the computer to understand different patterns and features in that picture. Convolution is like a window or filter that slides over the image, looking at small portions at a time. It calculates the numerical values based on the pixel values it covers. This operation helps the network identify important patterns, edges, and textures in the image. By applying multiple convolutions with different filters, the network learns to recognize various features in the data. . What is Pooling (Pool)? . After applying convolutions, the network might have extracted a lot of information, including some redundant or less significant details. Pooling helps reduce the amount of information while preserving the important features. It divides the image into small regions and selects the most significant value (e.g., the maximum value, known as max pooling) or calculates an average value (known as average pooling) within each region. This downsampling operation simplifies the representation of the data and makes the network more efficient by reducing the number of parameters it needs to learn. . import torch.optim as optim criterion = nn.CrossEntropyLoss() optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) . Failed to start the Kernel. Kernel Python 3.11.1 is not usable. Check the Jupyter output tab for more information. View Jupyter &lt;a href=&#39;command:jupyter.viewOutput&#39;&gt;log&lt;/a&gt; for further details. . for epoch in range(5): running_loss = 0.0 for i, data in enumerate(trainloader, 0): inputs, labels = data optimizer.zero_grad() outputs = net(inputs) loss = criterion(outputs, labels) loss.backward() optimizer.step() running_loss += loss.item() if i % 2000 == 1999: print(&#39;[%d, %5d] loss: %.3f&#39; % (epoch + 1, i + 1, running_loss / 2000)) running_loss = 0.0 print(&#39;Finished Training&#39;) . [1, 2000] loss: 2.188 [1, 4000] loss: 1.919 [1, 6000] loss: 1.755 [2, 2000] loss: 1.703 [2, 4000] loss: 1.652 [2, 6000] loss: 1.613 [3, 2000] loss: 1.580 [3, 4000] loss: 1.555 [3, 6000] loss: 1.532 [4, 2000] loss: 1.509 [4, 4000] loss: 1.500 [4, 6000] loss: 1.489 [5, 2000] loss: 1.465 [5, 4000] loss: 1.463 [5, 6000] loss: 1.442 Finished Training . What is loss? . The loss value is a metric that quantifies the difference between the predicted outputs of the model and the true labels of the training data. The loss value indicates how well the model is currently performing in terms of its ability to make accurate predictions. . During the training process, the goal is to minimize the loss function. The loss function is a mathematical function that calculates the error between the predicted outputs and the true labels. It provides a measure of how far off the model&#39;s predictions are from the desired outcomes. By iteratively adjusting the model&#39;s parameters using techniques like gradient descent, the loss value is reduced, leading to better predictions. . What is an optimizer? . In machine learning, an optimizer is an algorithm or method that is used to adjust the parameters of a model, such as the weights and biases in a Convolutional Neural Network (CNN), during the training process. The optimizer optimizes or updates the model&#39;s parameters based on the computed gradients of the loss function with respect to those parameters. . The goal of an optimizer is to find the optimal set of parameter values that minimize the loss function, effectively improving the model&#39;s performance. It achieves this by iteratively adjusting the parameters in a way that gradually reduces the loss value. . PATH = &#39;./cifar_net.pth&#39; torch.save(net.state_dict(), PATH) dataiter = iter(testloader) images, labels = next(dataiter) # print images imshow(torchvision.utils.make_grid(images)) print(&quot;Number of labels:&quot;, len(labels)) print(&quot;Labels tuple:&quot;, labels) labels = labels % 7 print(&#39;GroundTruth: &#39;, &#39; &#39;.join(&#39;%5s&#39; % classes[labels[j]] for j in range(min(8, len(labels))))) . Number of labels: 8 Labels tuple: tensor([3, 8, 8, 0, 6, 6, 1, 6]) GroundTruth: cat automobile automobile airplane frog frog automobile frog . outputs = net(images) _, predicted = torch.max(outputs, 1) print(&#39;Predicted: &#39;, &#39; &#39;.join(&#39;%5s&#39; % classes[predicted[j].item()] for j in range(len(predicted)))) print(&#39;Predicted Tensor:&#39;, predicted) print(&#39;Length of Predicted Tensor:&#39;, len(predicted)) . Predicted: cat ship ship airplane deer frog automobile frog Predicted Tensor: tensor([3, 8, 8, 0, 4, 6, 1, 6]) Length of Predicted Tensor: 8 . correct = 0 total = 0 with torch.no_grad(): for data in testloader: images, labels = data outputs = net(images) _, predicted = torch.max(outputs.data, 1) total += labels.size(0) correct += (predicted == labels).sum().item() print(&#39;Accuracy of the network on the 10000 test images: %d %%&#39; % ( 100 * correct / total)) . Accuracy of the network on the 10000 test images: 47 % . class_correct = list(0. for i in range(10)) class_total = list(0. for i in range(10)) with torch.no_grad(): for data in testloader: images, labels = data outputs = net(images) _, predicted = torch.max(outputs, 1) c = (predicted == labels).squeeze() for i in range(4): label = labels[i] class_correct[label] += c[i].item() class_total[label] += 1 for i in range(len(classes)): print(&#39;Accuracy of %5s : %2d %%&#39; % ( classes[i], 100 * class_correct[i] / class_total[i])) . Accuracy of airplane : 48 % Accuracy of automobile : 53 % Accuracy of bird : 45 % Accuracy of cat : 41 % Accuracy of deer : 36 % Accuracy of dog : 46 % Accuracy of frog : 56 % Accuracy of horse : 45 % Accuracy of ship : 68 % Accuracy of truck : 54 % .",
            "url": "https://rohitd3.github.io/manyFacesML/2023/06/04/CNN_usingPytorch-copy.html",
            "relUrl": "/2023/06/04/CNN_usingPytorch-copy.html",
            "date": " • Jun 4, 2023"
        }
        
    
  
    
        ,"post3": {
            "title": "What is test accuracy?",
            "content": "What is test accuracy? . In PyTorch, the term &quot;test accuracy&quot; typically refers to the accuracy of a trained model on a separate test dataset. It&#39;s used to evaluate the performance of a machine learning model. Test accuracy measures how well the model generalizes to unseen data (data that the model hasn&#39;t interacted with or seen yet) . Importance of test accuracy . Through training, the model is able to learn in order to better its own accuracy. This is paramount to machine learning; in context of our project, the model&#39;s accuracy in being able to identify what certain images represent is what our project is based on . Imports . In this part of our project, we are importing the optim module from the pytorch library, which allows us to use optimization algorithms. We then define the loss function to be criterion, with the use of CrossEntropyLoss(), which is used for multi-class classification problems. Then we initialize the optimizer, with a learning rate of .001, and a momentum of .9. The learning rate determines the step size at each iteration, and momentum helps accelerate convergence by considering previous gradients . import torch.optim as optim criterion = nn.CrossEntropyLoss() optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) . Training . By repeating this over and over, it learns from the training data. Overall, it works to minimize loss and improve accuracy. This repeats 5 epochs, which each epoch being going through the dataset one entire time. . for epoch in range(5): running_loss = 0.0 for i, data in enumerate(trainloader, 0): inputs, labels = data optimizer.zero_grad() ##clears gradients of optimizer outputs = net(inputs) loss = criterion(outputs, labels) loss.backward() optimizer.step() . Running loss incremented by loss of mini-batches . The item() method is used to take the loss value of the mini-batch that is currently being analyzed and add it to the value of the running loss. Then it checks if the current iteration is a multiple of 2000, which is used to print the average running loss every few iterations, allowing for the training progress to be monitored. It then prints the current epoch number, the iteration number, and the average running loss over the past 2000 iterations. Lastly, after the average running loss is printed, it is reset to 0 to calculate the loss for the next iterations. With the model training for 5 epochs, the training is only finished after it trains for 5 epochs. . Purpose . The purpose of this is to see the training progress because the average running loss is printed periodically, meaning that if the loss is decreasing over the epochs. The model is learning and improving itself, aka MACHINE LEARNING . for epoch in range(5): running_loss = 0.0 for i, data in enumerate(trainloader, 0): inputs, labels = data optimizer.zero_grad() outputs = net(inputs) loss = criterion(outputs, labels) loss.backward() optimizer.step() # Start of running loss running_loss += loss.item() if i % 2000 == 1999: print(&#39;[%d, %5d] loss: %.3f&#39; % (epoch + 1, i + 1, running_loss / 2000)) running_loss = 0.0 print(&#39;Finished Training&#39;) .",
            "url": "https://rohitd3.github.io/manyFacesML/2023/06/04/CNN_test_accuracy.html",
            "relUrl": "/2023/06/04/CNN_test_accuracy.html",
            "date": " • Jun 4, 2023"
        }
        
    
  
    
        ,"post4": {
            "title": "CNN face detecting",
            "content": ". !pip install torch torchvision !pip install torchviz !pip install --upgrade torch torchvision %matplotlib inline import matplotlib.pyplot as plt import torch from torchvision import datasets, transforms import helper . Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/ Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118) Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118) Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0) Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0) Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1) Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1) Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2) Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0) Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-&gt;torch) (3.25.2) Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-&gt;torch) (16.0.5) Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4) Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1) Requirement already satisfied: pillow!=8.3.*,&gt;=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0) Requirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-&gt;torch) (2.1.2) Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;torchvision) (1.26.15) Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;torchvision) (2022.12.7) Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;torchvision) (2.0.12) Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;torchvision) (3.4) Requirement already satisfied: mpmath&gt;=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-&gt;torch) (1.3.0) Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/ Collecting torchviz Downloading torchviz-0.0.2.tar.gz (4.9 kB) Preparing metadata (setup.py) ... done Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchviz) (2.0.1+cu118) Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from torchviz) (0.20.1) Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch-&gt;torchviz) (3.12.0) Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch-&gt;torchviz) (4.5.0) Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch-&gt;torchviz) (1.11.1) Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch-&gt;torchviz) (3.1) Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;torchviz) (3.1.2) Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;torchviz) (2.0.0) Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-&gt;torch-&gt;torchviz) (3.25.2) Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-&gt;torch-&gt;torchviz) (16.0.5) Requirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-&gt;torch-&gt;torchviz) (2.1.2) Requirement already satisfied: mpmath&gt;=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-&gt;torch-&gt;torchviz) (1.3.0) Building wheels for collected packages: torchviz Building wheel for torchviz (setup.py) ... done Created wheel for torchviz: filename=torchviz-0.0.2-py3-none-any.whl size=4131 sha256=c35883c0fc16e43c0728c7edb48d38965b8c91c0b75bf29678c36c9da06db591 Stored in directory: /root/.cache/pip/wheels/4c/97/88/a02973217949e0db0c9f4346d154085f4725f99c4f15a87094 Successfully built torchviz Installing collected packages: torchviz Successfully installed torchviz-0.0.2 Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/ Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118) Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118) Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0) Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0) Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1) Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1) Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2) Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0) Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-&gt;torch) (3.25.2) Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-&gt;torch) (16.0.5) Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4) Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1) Requirement already satisfied: pillow!=8.3.*,&gt;=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0) Requirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-&gt;torch) (2.1.2) Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;torchvision) (1.26.15) Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;torchvision) (2022.12.7) Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;torchvision) (2.0.12) Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;torchvision) (3.4) Requirement already satisfied: mpmath&gt;=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-&gt;torch) (1.3.0) . import os def restart_runtime(): os.kill(os.getpid(), 9) restart_runtime() . from google.colab import drive from google.colab import files from PIL import Image drive.mount(&#39;/content/gdrive&#39;) . Mounted at /content/gdrive . data_directory_face = &#39;/content/gdrive/MyDrive/FACEML/face&#39; . # Keep the Image width, height a multiple of 4. #This will ensure after Conv2D with 5X5 filter, and MaxPool(2,2) TWICE, # the values height2, width2 are still integers ImageWidth=384 ImageHeight=384 #the most common choices for convolution filter kernel sizes appear to be square shape of sizes 3X3, 5X5 #smaller sized kernel allows for more granular information. Here 5X5 is used. #Maxpool is needed when the image is larger. It keeps the item with the maximum value. convKernelSize1 =5 convKernelSize2 =5 maxpoolKernelSize = 2 #conv1 Input Channel is default 3 for R, G, B channels directly from the colored Image convOutputChannel1 = 16 #convInputChannel2 is the same as the convOutputChannel1 convOutputChannel2 = 32 linearOut1 = 256 linearOut2 = 84 dropOutValue = 0.2 # for the first convolution and max pool height1=int((ImageHeight - convKernelSize1 + 1)/maxpoolKernelSize) width1=int((ImageWidth - convKernelSize1 + 1)/maxpoolKernelSize) # for the second convolution and max pool height2=int((height1 - convKernelSize2 + 1)/maxpoolKernelSize) width2=int((width1 - convKernelSize2 + 1)/maxpoolKernelSize) print(&quot; ImageWidth = &quot;, ImageWidth) print(&quot; ImageHeight = &quot;, ImageHeight) print(&quot; width1 = &quot;, width1) print(&quot; height1 = &quot;, height1) print(&quot; width2 = &quot;, width2) print(&quot; height2 = &quot;, height2) . ImageWidth = 384 ImageHeight = 384 width1 = 190 height1 = 190 width2 = 93 height2 = 93 . import torch import torchvision import numpy as np from torchvision import datasets import torchvision.transforms as transforms from torch.utils.data.sampler import SubsetRandomSampler import matplotlib.pyplot as plt # how many samples per batch to load batch_size = 16 # percentage of training set to use as validation test_size = 0.3 valid_size = 0.1 # Preprocessing steps # Horizontal Flip, Random Rotation, convert image array into PyTorch and normalize train_transform = transforms.Compose([ transforms.RandomHorizontalFlip(), transforms.RandomRotation(60), transforms.Resize(size=(ImageWidth,ImageHeight)), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # need to keep these transforms, at least do resize all images to same size and co ]) . data = datasets.ImageFolder(data_directory_face,transform=train_transform) plt.show(data) . The data needs to be split in Train, Test and validation set before training. . Train set will be used to train the model. | Validation set will be used for validating the model after each epoch. | Test set will be used to evaluate the model once it is trained. | . num_data = len(data) print(&quot;num_data = &quot;, num_data) indices_data = list(range(num_data)) np.random.shuffle(indices_data) #For test and training split_tt = int(np.floor(test_size * num_data)) # numpy.floor function operates element-wise on the input array, # returning a new array with the same shape as the input. # It rounds down each element of the input array to the nearest # integer that is less than or equal to that element train_idx, test_idx = indices_data[split_tt:], indices_data[:split_tt] print(&quot; n train_idx = &quot;, train_idx) print(&quot; n test_idx = &quot;, test_idx) #From training separate data For validation (for each epoch) num_train = len(train_idx) indices_train = list(range(num_train)) np.random.shuffle(indices_train) split_tv = int(np.floor(valid_size * num_train)) train_new_idx, valid_idx = indices_train[split_tv:],indices_train[:split_tv] print(&quot; n train_new_idx = &quot;, train_new_idx) print(&quot; n valid_idx = &quot;, valid_idx) # define samplers for obtaining training and validation batches train_sampler = SubsetRandomSampler(train_new_idx) valid_sampler = SubsetRandomSampler(valid_idx) test_sampler = SubsetRandomSampler(test_idx) . num_data = 400 train_idx = [136, 312, 256, 390, 111, 206, 13, 38, 331, 16, 385, 173, 192, 259, 181, 298, 80, 285, 68, 37, 384, 174, 317, 315, 205, 248, 109, 70, 203, 91, 71, 246, 188, 186, 260, 22, 171, 26, 60, 170, 314, 119, 202, 366, 231, 269, 335, 152, 3, 305, 100, 310, 15, 41, 97, 357, 287, 311, 11, 153, 212, 232, 308, 2, 82, 58, 350, 185, 235, 143, 20, 79, 142, 337, 392, 222, 114, 62, 363, 46, 193, 356, 115, 49, 168, 236, 342, 138, 129, 54, 234, 220, 396, 107, 123, 128, 140, 237, 276, 362, 72, 81, 169, 293, 162, 190, 132, 215, 272, 209, 53, 377, 271, 145, 354, 28, 29, 167, 200, 266, 34, 321, 324, 150, 353, 10, 398, 278, 51, 380, 320, 146, 268, 371, 23, 365, 322, 242, 133, 30, 230, 94, 40, 25, 130, 177, 4, 86, 261, 349, 59, 180, 112, 35, 57, 21, 77, 252, 290, 233, 96, 243, 52, 108, 338, 283, 151, 211, 294, 303, 255, 343, 196, 368, 42, 50, 149, 157, 69, 55, 90, 73, 247, 75, 121, 197, 139, 391, 61, 263, 221, 379, 328, 148, 358, 274, 43, 346, 191, 332, 340, 67, 48, 238, 399, 347, 249, 280, 389, 207, 31, 85, 375, 336, 126, 279, 156, 316, 216, 318, 104, 39, 195, 65, 125, 122, 326, 273, 175, 147, 301, 341, 370, 264, 84, 257, 306, 178, 131, 56, 254, 393, 7, 227, 378, 36, 372, 253, 360, 74, 141, 110, 388, 348, 288, 218, 381, 159, 154, 95, 265, 397, 217, 103, 374, 137, 127, 155, 172, 164, 359, 224, 325, 345, 239, 124, 300, 210, 339, 214] test_idx = [302, 160, 289, 258, 63, 5, 165, 262, 183, 17, 313, 394, 106, 204, 24, 295, 330, 163, 213, 199, 251, 158, 87, 309, 352, 102, 105, 225, 329, 373, 267, 12, 297, 226, 201, 244, 116, 292, 286, 117, 281, 184, 47, 45, 6, 369, 323, 367, 14, 351, 299, 32, 282, 179, 1, 9, 296, 319, 44, 307, 245, 334, 387, 101, 198, 194, 89, 118, 395, 361, 284, 376, 355, 134, 8, 270, 135, 327, 219, 92, 386, 78, 275, 88, 176, 161, 344, 250, 291, 229, 83, 241, 93, 277, 304, 189, 333, 382, 223, 64, 144, 76, 187, 228, 98, 99, 208, 19, 27, 240, 182, 383, 18, 364, 120, 0, 66, 33, 166, 113] train_new_idx = [115, 161, 50, 249, 171, 111, 201, 169, 95, 91, 97, 81, 173, 137, 19, 197, 99, 89, 266, 205, 85, 279, 187, 46, 62, 139, 175, 242, 48, 10, 136, 269, 140, 219, 267, 51, 149, 255, 77, 262, 146, 185, 278, 259, 202, 44, 190, 71, 84, 5, 98, 17, 225, 138, 271, 229, 58, 132, 181, 12, 52, 14, 125, 82, 199, 120, 18, 154, 153, 164, 210, 2, 248, 0, 252, 212, 224, 147, 13, 207, 47, 220, 265, 230, 92, 261, 80, 135, 168, 214, 114, 131, 198, 157, 172, 189, 273, 232, 241, 105, 26, 256, 209, 276, 231, 208, 22, 243, 56, 179, 3, 60, 263, 200, 117, 126, 184, 124, 234, 107, 73, 148, 191, 86, 11, 28, 237, 251, 193, 121, 61, 221, 20, 79, 160, 43, 6, 9, 104, 59, 253, 101, 141, 55, 264, 65, 128, 31, 182, 103, 23, 118, 134, 145, 102, 218, 260, 257, 7, 88, 15, 49, 112, 72, 186, 78, 268, 203, 39, 254, 166, 204, 68, 238, 1, 93, 116, 155, 127, 240, 244, 45, 122, 87, 109, 223, 250, 63, 180, 196, 36, 34, 228, 247, 215, 35, 106, 272, 150, 174, 233, 194, 144, 53, 152, 21, 57, 178, 162, 8, 32, 110, 142, 165, 170, 217, 258, 123, 96, 177, 133, 159, 226, 100, 277, 183, 83, 156, 113, 94, 151, 158, 119, 216, 90, 176, 236, 108, 25, 33, 70, 24, 27, 54, 130, 29, 16, 167, 192, 4, 40, 222] valid_idx = [30, 211, 213, 67, 75, 41, 245, 274, 64, 76, 163, 195, 66, 69, 275, 270, 143, 227, 42, 37, 235, 239, 246, 129, 74, 38, 188, 206] . # train_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, sampler=train_sampler, num_workers=1, transform=train_transform) train_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, sampler=train_sampler, num_workers=1) # only running the data augmentation on the training data, double check if works valid_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, sampler=valid_sampler, num_workers=1) test_loader = torch.utils.data.DataLoader(data, sampler = test_sampler, batch_size=batch_size, num_workers=1) # variable representing classes of the images classes = [0,1] # labeling either 0 (negative) or 1 (positive) total_length = len(test_loader)*batch_size + len(valid_loader)*batch_size + len(train_loader)*batch_size print(&quot;total_length = &quot;, total_length) . total_length = 416 . for batch in valid_loader: print(&quot;batch[0].size() = &quot;, batch[0].size()) . batch[0].size() = torch.Size([16, 3, 384, 384]) batch[0].size() = torch.Size([12, 3, 384, 384]) . import matplotlib.pyplot as plt %matplotlib inline # helper function to un-normalize and display an image def imshow(img): img = img / 2 + 0.5 # unnormalize plt.imshow(np.transpose(img, (1, 2, 0))) # convert from Tensor image def imshownormal(img): img = img / 2 + 0.5 # unnormalize plt.imshownormal(np.transpose(img, (0, 0, 0))) # convert from Tensor image # obtain one batch of training images dataiter = iter(train_loader) images, labels = next(dataiter) images = images.numpy() # convert images to numpy for display # plot the images in the batch, along with the corresponding labels . num_of_image_to_display = 16 fig = plt.figure(figsize=(num_of_image_to_display, 4)) for idx in np.arange(num_of_image_to_display): ax = fig.add_subplot(2, int(num_of_image_to_display/2), idx+1, xticks=[], yticks=[]) imshow(images[idx]) ax.set_title(classes[labels[idx]]) display(plt.show()) plt.close() . None . import torch import numpy as np from torchvision import datasets import torchvision.transforms as transforms from torch.utils.data.sampler import SubsetRandomSampler import torch.nn as nn import torch.optim as optim import torch.utils.data as data import torchvision.models as models from torch.autograd import Variable . What is pytorch? . PyTorch is an open-source machine learning library primarily used for deep learning tasks. It is developed by Facebook&#39;s AI Research Lab and provides a Python interface for building and training neural networks. PyTorch is known for its dynamic computational graph, which allows users to define and modify computational graphs on-the-fly during runtime. . Neural network building blocks: PyTorch provides a rich set of pre-built modules and classes for building neural networks, such as various types of layers (e.g., fully connected, convolutional, recurrent), activation functions, loss functions, and optimizers. . GPU acceleration: PyTorch seamlessly integrates with CUDA, a parallel computing platform, to leverage the power of NVIDIA GPUs for faster training and inference. . import torch.nn as nn import torch.nn.functional as F train_on_gpu = torch.cuda.is_available() print(&quot;train_on_gpu = &quot;, train_on_gpu) class Net(nn.Module): def __init__(self): super(Net, self).__init__() # define the two convolutional operations # conv1 Input Channel =3 for the R, G, B channels directly from the Image self.conv1 = nn.Conv2d(3, convOutputChannel1, convKernelSize1) self.conv2 = nn.Conv2d(convOutputChannel1, convOutputChannel2, convKernelSize2) # define the max pool operation self.pool = nn.MaxPool2d(maxpoolKernelSize, maxpoolKernelSize) self.dropout = nn.Dropout(dropOutValue) # define the Linear (fully connected) operations self.fc1 = nn.Linear(convOutputChannel2* height2 * width2, linearOut1) self.fc2 = nn.Linear(linearOut1, linearOut2) self.fc3 = nn.Linear(linearOut2, 2) self.softmax = nn.LogSoftmax(dim=1) def forward(self, x): # add sequence of convolutional, relu and max pooling layers x = self.pool(F.relu(self.conv1(x))) x = self.pool(F.relu(self.conv2(x))) x = self.dropout(x) # the linearization needs to start with = # of output channels * height2 * width2 x = x.view(-1, convOutputChannel2 * height2 * width2) x = F.relu(self.fc1(x)) x = self.dropout(F.relu(self.fc2(x))) x = self.softmax(self.fc3(x)) return x . Training the Model . Finally comes the training part. Here you need to decide two crucial things: Loss function and optimizer. There are various choices like SGD, Adam, etc.. for the optimizer. used Cross-Entropy loss, which is a popular choice in the case of classification problems. should also set a learning rate, which decides how fast your model learns. . model = Net() print(&quot;++++++++++++ print the model ++++++++&quot;) print(model) print(&quot;+++++++++++++++++++++++++++++++++++++&quot;) # move tensors to GPU if CUDA is available if train_on_gpu: model.cuda() . import torch.optim as optim # specify loss function criterion = torch.nn.CrossEntropyLoss() learning_rate = 0.003 # test with Stochastic gradient descent optimizer - optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate, momentum= 0.9) . n_epochs = 5 # you may increase this number to train a final model valid_loss_min = np.Inf # track change in validation loss . make_loss_graph function takes in data_list_val and data_list_train as input, which are lists of loss values for validation and training data. It plots these values on a graph and displays it. . def make_loss_graph(data_list_val, data_list_train): plt.close() plt.title(&quot;Training and Validation Loss per Epoch&quot;) val_label = &quot;Validation Loss &quot; train_label = &quot;Training Loss &quot; assert len(data_list_val) == len(data_list_train) ##makes sure the lengths of each are the same, will give error if not length = len(data_list_train) - 1 plt.plot(data_list_val, label=val_label) ##validation data plt.plot(data_list_train, label=train_label) ##training data #plt.xlim((epoch_skip, length)) plt.xlabel(&#39;Epochs&#39;) plt.legend() plt.grid() plt.axis([0, 10, 0, 10]) display(plt.show()) ##displays plot plt.close() . Underfitting and overfitting . Reasons for Underfitting: . High bias and low variance The size of the training dataset used is not enough. The model is too simple. Training data is not cleaned and also contains noise in it. . Techniques to reduce underfitting: . Increase model complexity Increase the number of features, performing feature engineering Remove noise from the data. Increase the number of epochs or increase the duration of training to get better results. . https://www.geeksforgeeks.org/underfitting-and-overfitting-in-machine-learning/# . This shows a training loop for a machine learning model and then calls the make_loss_graph function to visualize the training and validation loss per epoch. The purpose of this code is to train a machine learning model over multiple epochs, track the training and validation loss, and visualize the loss values using the make_loss_graph function. . list_val_loss_all_epoch =[] list_train_loss_all_epoch =[] for epoch in range(1, n_epochs+1): print(&#39;####### EPOCH &#39;, epoch) # keep track of training and validation loss train_loss = 0.0 valid_loss = 0.0 train_items = 0.0 valid_items = 0.0 ################### # train the model # ################### model.train() print(&#39; len(train_loader.dataset) = &#39;, len(train_loader.dataset)) for data, target in train_loader: # move tensors to GPU if CUDA is available if train_on_gpu: data, target = data.cuda(), target.cuda() # clear the gradients of all optimized variables optimizer.zero_grad() # forward pass: compute predicted outputs by passing inputs to the model output = model(data) # calculate the batch loss loss = criterion(output, target) # backward pass: compute gradient of the loss with respect to model parameters loss.backward() # perform a single optimization step (parameter update) optimizer.step() # update training loss print(&#39; train loss item = &#39;, loss.item()*data.size(0)) train_loss += loss.item()*data.size(0) train_items +=1 ###################### # validate or evaluate the model # # To evaluate the model, it should be changed from model.train() to model.eval() ###################### model.eval() print(&#39; len(valid_loader.dataset) = &#39;, len(valid_loader.dataset)) for data, target in valid_loader: # move tensors to GPU if CUDA is available if train_on_gpu: data, target = data.cuda(), target.cuda() # forward pass: compute predicted outputs by passing inputs to the model output = model(data) # calculate the batch loss loss = criterion(output, target) # update average validation loss print(&#39; valid loss item = &#39;, loss.item()*data.size(0)) valid_loss += loss.item()*data.size(0) valid_items +=1 # calculate average losses print(&#39; n train_loss = &#39;, train_loss) print(&#39; valid_loss = &#39;, valid_loss) print(&#39; n train_items = &#39;, train_items) print(&#39; valid_items = &#39;, valid_items) #train_loss = train_loss/len(train_loader.dataset) # incorrect: this was averaging over 500 (the total amount of images available) #valid_loss = valid_loss/len(valid_loader.dataset) train_loss = train_loss/train_items # this is averaging correctly valid_loss = valid_loss/valid_items print(&#39; n average train_loss = &#39;, train_loss) print(&#39; average valid_loss = &#39;, valid_loss) list_val_loss_all_epoch.append(valid_loss) list_train_loss_all_epoch.append(train_loss) # print training/validation statistics print(&#39;Epoch: {} t Average Training Loss: {:.6f} t Average Validation Loss: {:.6f}&#39;.format( epoch, train_loss, valid_loss)) # save model if validation loss has decreased if valid_loss &lt;= valid_loss_min: print(&#39;Validation loss decreased ({:.6f} --&gt; {:.6f}). Saving model ...&#39;.format( valid_loss_min, valid_loss)) torch.save(model.state_dict(), &#39;model_cifar.pt&#39;) valid_loss_min = valid_loss make_loss_graph(list_val_loss_all_epoch, list_train_loss_all_epoch) . # Analysis of the Model # plotting loss and accuracy over epochs to see how it changed over training ###################################################### print(&quot; n **************** START TEST ******************* &quot;) # plot the accuracy # confusion matrix # dont train for 700 epochs - do for less ~20 # track test loss test_loss = 0.0 class_correct = list(0. for i in range(2)) class_total = list(0. for i in range(2)) model.eval() i=1 # iterate over test data len(test_loader) for data, target in test_loader: i=i+1 if len(target)!=batch_size: continue # move tensors to GPU if CUDA is available if train_on_gpu: data, target = data.cuda(), target.cuda() # forward pass: compute predicted outputs by passing inputs to the model output = model(data) # calculate the batch loss loss = criterion(output, target) # update test loss test_loss += loss.item()*data.size(0) # convert output probabilities to predicted class _, pred = torch.max(output, 1) # compare predictions to true label correct_tensor = pred.eq(target.data.view_as(pred)) correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy()) # calculate test accuracy for each object class # print(target) for i in range(batch_size): label = target.data[i] class_correct[label] += correct[i].item() class_total[label] += 1 # average test loss test_loss = test_loss/len(test_loader.dataset) print(&#39;Test Loss: {:.6f} n&#39;.format(test_loss)) for i in range(2): if class_total[i] &gt; 0: print(&#39;Test Accuracy of %5s: %2d%% (%2d/%2d)&#39; % ( classes[i], 100 * class_correct[i] / class_total[i], np.sum(class_correct[i]), np.sum(class_total[i]))) else: print(&#39;Test Accuracy of %5s: N/A (no training examples)&#39; % (classes[i])) print(&#39; nTest Accuracy (Overall): %2d%% (%2d/%2d)&#39; % ( 100. * np.sum(class_correct) / np.sum(class_total), np.sum(class_correct), np.sum(class_total))) .",
            "url": "https://rohitd3.github.io/manyFacesML/2023/06/04/CNN_faces.html",
            "relUrl": "/2023/06/04/CNN_faces.html",
            "date": " • Jun 4, 2023"
        }
        
    
  

  
  

  
  

  

  
  

  

  
  

  
  

  
  

  
  

  
      ,"page9": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://rohitd3.github.io/manyFacesML/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}
{
  
    
        "post0": {
            "title": "Identifying faces",
            "content": "!pip install torch torchvision !pip install torchviz !pip install --upgrade torch torchvision # the Pandas mismatch hasn&#39;t been a problem, because we aren&#39;t using it in our code # ERROR: google-colab 1.0.0 has requirement pandas~=1.0.0; python_version &gt;= &quot;3.0&quot;, but you&#39;ll have pandas 1.1.0 which is incompatible. . Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/ Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1) Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2) Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0) Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0) Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1) Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1) Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2) Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.99) Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.99) Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.101) Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch) (8.5.0.96) Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch) (11.10.3.66) Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch) (10.9.0.58) Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch) (10.2.10.91) Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.0.1) Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.4.91) Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch) (2.14.3) Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.91) Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0) Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66-&gt;torch) (67.7.2) Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66-&gt;torch) (0.40.0) Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-&gt;torch) (3.25.2) Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-&gt;torch) (16.0.3) Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4) Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1) Requirement already satisfied: pillow!=8.3.*,&gt;=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0) Requirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-&gt;torch) (2.1.2) Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;torchvision) (1.26.15) Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;torchvision) (2022.12.7) Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;torchvision) (2.0.12) Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;torchvision) (3.4) Requirement already satisfied: mpmath&gt;=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-&gt;torch) (1.3.0) Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/ Requirement already satisfied: torchviz in /usr/local/lib/python3.10/dist-packages (0.0.2) Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchviz) (2.0.1) Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from torchviz) (0.20.1) Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch-&gt;torchviz) (3.12.0) Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch-&gt;torchviz) (4.5.0) Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch-&gt;torchviz) (1.11.1) Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch-&gt;torchviz) (3.1) Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;torchviz) (3.1.2) Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;torchviz) (11.7.99) Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;torchviz) (11.7.99) Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;torchviz) (11.7.101) Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;torchviz) (8.5.0.96) Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;torchviz) (11.10.3.66) Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;torchviz) (10.9.0.58) Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;torchviz) (10.2.10.91) Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;torchviz) (11.4.0.1) Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;torchviz) (11.7.4.91) Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;torchviz) (2.14.3) Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;torchviz) (11.7.91) Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;torchviz) (2.0.0) Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66-&gt;torch-&gt;torchviz) (67.7.2) Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66-&gt;torch-&gt;torchviz) (0.40.0) Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-&gt;torch-&gt;torchviz) (3.25.2) Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-&gt;torch-&gt;torchviz) (16.0.3) Requirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-&gt;torch-&gt;torchviz) (2.1.2) Requirement already satisfied: mpmath&gt;=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-&gt;torch-&gt;torchviz) (1.3.0) Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/ Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1) Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2) Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0) Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0) Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1) Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1) Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2) Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.99) Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.99) Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.101) Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch) (8.5.0.96) Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch) (11.10.3.66) Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch) (10.9.0.58) Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch) (10.2.10.91) Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.0.1) Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.4.91) Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch) (2.14.3) Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.91) Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0) Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66-&gt;torch) (67.7.2) Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66-&gt;torch) (0.40.0) Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-&gt;torch) (3.25.2) Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-&gt;torch) (16.0.3) Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4) Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1) Requirement already satisfied: pillow!=8.3.*,&gt;=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0) Requirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-&gt;torch) (2.1.2) Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;torchvision) (1.26.15) Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;torchvision) (2022.12.7) Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;torchvision) (2.0.12) Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;torchvision) (3.4) Requirement already satisfied: mpmath&gt;=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-&gt;torch) (1.3.0) . import os def restart_runtime(): os.kill(os.getpid(), 9) restart_runtime() . # Websites for Binary classification on Images # https://github.com/jayrodge/Binary-Image-Classifier-PyTorch # https://github.com/jayrodge/Binary-Image-Classifier-PyTorch/blob/master/Binary_face_classifier.ipynb # https://hackernoon.com/binary-face-classifier-using-pytorch-2d835ccb7816 - this website explains the following code import torch import numpy as np from torchvision import datasets import torchvision.transforms as transforms from torch.utils.data.sampler import SubsetRandomSampler # import torch.nn as nn # import torch.optim as optim # import torch.utils.data as data # import torchvision.models as models # # from torch.autograd import Variable # from torchvision.models.vgg import model_urls # from torchviz import make_dot # The following program is obtained from: # https://github.com/jayrodge/Binary-Image-Classifier-PyTorch/blob/master/Binary_face_classifier.ipynb # # Visualization tool # https://stackoverflow.com/questions/52468956/how-do-i-visualize-a-net-in-pytorch from google.colab import drive from google.colab import files from PIL import Image drive.mount(&#39;/content/gdrive&#39;) ######################################################### # Processing the Dataset #- # You might often need to process the image data before passing it to the model. # For example, if the sizes of all images are different (which often the case in large datasets), # then your model will throw an error. So resize them, and you can consider rescaling the pixel values also. # Apart from this, you can perform diverse transforms for data augmentation. # An elegant way to apply multiple transforms is using transform.compose() as shown below. # # When comes to loading/ preprocessing the data PyTorch is much simpler as compared to other libraries. # However, PyTorch has a built-in function called transforms using which you can perform all your pre-processing tasks ############################################################## # how many samples per batch to load batch_size = 16 # percentage of training set to use as validation test_size = 0.3 # test size is 30% of the total images that means training size is 70% of the total images valid_size = 0.1 # validation is 10% of the training image; validation comes before testing and validates each input ImageWidth=384 ImageHeight=384 #the most common choices for convolution filter kernel sizes appear to be square shape of sizes 3X3, 5X5 #smaller sized kernel allows for more granular information. Here 5X5 is used. #Maxpool is needed when the image is larger. It keeps the item with the maximum value. convKernelSize1 =5 convKernelSize2 =5 maxpoolKernelSize = 2 #conv1 Input Channel is defalut 3 for R, G, B channels directly from the colored Image convOutputChannel1 = 16 #convInputChannel2 is the same as the convOutputChannel1 convOutputChannel2 = 32 linearOut1 = 256 linearOut2 = 84 dropOutValue = 0.2 # # for the first convolution and max pool height1=int((ImageHeight - convKernelSize1 + 1)/maxpoolKernelSize) width1=int((ImageWidth - convKernelSize1 + 1)/maxpoolKernelSize) # for the second convolution and max pool height2=int((height1 - convKernelSize2 + 1)/maxpoolKernelSize) width2=int((width1 - convKernelSize2 + 1)/maxpoolKernelSize) print(&quot; ImageWidth = &quot;, ImageWidth) print(&quot; ImageHeight = &quot;, ImageHeight) print(&quot; width1 = &quot;, width1) print(&quot; height1 = &quot;, height1) print(&quot; width2 = &quot;, width2) print(&quot; height2 = &quot;, height2) train_transform = transforms.Compose([ transforms.RandomHorizontalFlip(), transforms.RandomRotation(10), transforms.Resize(size=(ImageWidth,ImageHeight)), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # need to keep these transforms, at least do resize all images to same size and co ]) ########################################################################### # data_directory_face = &#39;/content/gdrive/MyDrive/DNN_ML/face&#39; print(&quot; n n **************** START LOADING DATA AND PROCESSING ******************* &quot;) ########### # Select one of the above data_directory_XYZ # Depending on what you want to run. # You can change this part for different tests ############ data = datasets.ImageFolder(data_directory_face,transform=train_transform) # data = datasets.ImageFolder(data_directory_tumor) # The data needs to be split in Train, Test and validation set before training. # - Train set will be used to train the model. # - Validation set will be used for validating the model after each epoch. # - Test set will be used to evaluate the model once it is trained. num_data = len(data) print(&quot;num_data = &quot;, num_data) indices_data = list(range(num_data)) np.random.shuffle(indices_data) #For test and training # split_tt = int(np.floor(test_size * num_data)) train_idx, test_idx = indices_data[split_tt:], indices_data[:split_tt] print(&quot; n train_idx = &quot;, train_idx) print(&quot; n test_idx = &quot;, test_idx) #From Training separate something For validation (for each epoch) # num_train = len(train_idx) indices_train = list(range(num_train)) np.random.shuffle(indices_train) split_tv = int(np.floor(valid_size * num_train)) train_new_idx, valid_idx = indices_train[split_tv:],indices_train[:split_tv] print(&quot; n n train_new_idx = &quot;, train_new_idx) print(&quot; n valid_idx = &quot;, valid_idx) # define samplers for obtaining training and validation batches train_sampler = SubsetRandomSampler(train_new_idx) valid_sampler = SubsetRandomSampler(valid_idx) test_sampler = SubsetRandomSampler(test_idx) # Loaders contains the data in tuple format (Image in form of tensor, label) train_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, sampler=train_sampler, num_workers=1) # only running the data augmentation on the training data, double check if works valid_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, sampler=valid_sampler, num_workers=1) test_loader = torch.utils.data.DataLoader(data, sampler = test_sampler, batch_size=batch_size, num_workers=1) # variable representing classes of the images classes = [0,1] # labeling either 0 (negative) or 1 (positive) total_length = len(test_loader)*batch_size + len(valid_loader)*batch_size + len(train_loader)*batch_size print(&quot;total_length = &quot;, total_length) for batch in valid_loader: print(&quot;batch[0].size() = &quot;, batch[0].size()) import matplotlib.pyplot as plt %matplotlib inline # helper function to un-normalize and display an image def imshow(img): img = img / 2 + 0.5 # unnormalize plt.imshow(np.transpose(img, (1, 2, 0))) # convert from Tensor image # obtain one batch of training images dataiter = iter(train_loader) images, labels = next(dataiter) images = images.numpy() # convert images to numpy for display # plot the images in the batch, along with the corresponding labels fig = plt.figure(figsize=(10, 4)) print(&quot; display images &quot;) # display some images with Labels to see if labeling appears correct no_of_image_to_display = 10 for idx in np.arange(no_of_image_to_display): ax = fig.add_subplot(2, no_of_image_to_display/2, idx+1, xticks=[], yticks=[]) imshow(images[idx]) ax.set_title(classes[labels[idx]]) display(plt.show()) plt.close() # Building the Model: Decrypting the layers # # The model class definition should always have __init__() method. In this, we will initialize the blocks/layers and other parameters. # Talking about the neural network layers, there are 3 main types in image classification: convolutional, max pooling, and dropout . # Convolution layers: Convolutional layers will extract features from the input image and generate feature maps/activations. # You can decide how many activations you want using the filters argument. # Basically, when you apply convolution upon an image, the kernel will pass over the entire image in small parts, # and it will give an activation. It is demonstrated in the below image. # Pooling Layers # When we use conv2d layers, we end up with a lot of feature maps that occupy high computational space. # In order to decrease the computational time and space required, you can use Max pooling or average pooling. # For each patch/group of the map, only the maximum is chosen to form the output. # The below image clearly demonstrates the work. # Dropout Layers # You can guess its function from the name itself! It drops out like 10-20% of the data. # Overfitting is a common problem when you are training over the same data for many iterations/epochs. # By dropping out a randomly chosen 10% of data, the model will be able to generalize more to new data. # This concludes with a brief description of the layers we have used in our code. # Note that the final layer has output as 2, as it is binary classification. . Mounted at /content/gdrive ImageWidth = 384 ImageHeight = 384 width1 = 190 height1 = 190 width2 = 93 height2 = 93 **************** START LOADING DATA AND PROCESSING ******************* num_data = 400 train_idx = [233, 261, 54, 14, 246, 47, 309, 360, 215, 189, 131, 22, 252, 25, 186, 164, 66, 253, 351, 84, 33, 280, 155, 334, 133, 137, 239, 90, 3, 288, 219, 106, 160, 234, 313, 210, 172, 220, 74, 180, 173, 248, 391, 389, 8, 35, 70, 62, 130, 369, 39, 107, 328, 376, 48, 96, 310, 312, 316, 78, 322, 135, 16, 81, 147, 355, 341, 191, 365, 42, 257, 188, 176, 283, 317, 128, 352, 153, 41, 353, 386, 15, 304, 17, 20, 179, 2, 238, 320, 91, 292, 77, 113, 354, 331, 291, 300, 27, 101, 152, 4, 229, 80, 242, 230, 86, 209, 255, 357, 208, 34, 75, 104, 5, 375, 216, 293, 221, 166, 398, 139, 149, 314, 59, 199, 350, 387, 228, 323, 125, 298, 315, 264, 67, 60, 397, 26, 218, 142, 19, 124, 192, 185, 243, 311, 196, 79, 49, 203, 279, 61, 36, 69, 336, 284, 390, 281, 115, 269, 213, 295, 324, 382, 6, 117, 92, 294, 207, 163, 184, 103, 335, 177, 272, 301, 394, 342, 169, 162, 287, 87, 57, 373, 235, 114, 205, 399, 332, 64, 23, 273, 379, 225, 378, 119, 136, 296, 111, 381, 345, 277, 259, 359, 201, 10, 156, 374, 231, 105, 222, 145, 250, 108, 262, 385, 43, 141, 299, 362, 232, 58, 282, 223, 195, 285, 366, 327, 170, 290, 138, 356, 198, 50, 11, 71, 349, 206, 120, 346, 110, 347, 40, 319, 175, 21, 7, 102, 97, 364, 276, 384, 396, 181, 63, 28, 241, 202, 126, 340, 159, 174, 275, 65, 371, 370, 143, 271, 268, 167, 116, 100, 89, 140, 270, 393, 144, 306, 289, 150, 154] test_idx = [348, 254, 227, 157, 182, 333, 380, 122, 112, 392, 226, 51, 367, 183, 123, 88, 190, 95, 224, 338, 9, 158, 18, 286, 32, 329, 83, 344, 358, 53, 240, 134, 302, 129, 330, 194, 161, 297, 343, 118, 98, 260, 388, 266, 267, 395, 72, 1, 321, 307, 168, 217, 204, 37, 171, 361, 0, 132, 31, 372, 56, 38, 187, 325, 237, 45, 82, 308, 263, 200, 383, 256, 165, 148, 24, 52, 377, 93, 278, 245, 251, 337, 193, 44, 121, 244, 363, 247, 30, 178, 339, 13, 236, 214, 368, 127, 151, 29, 73, 109, 68, 55, 211, 318, 12, 303, 197, 85, 46, 212, 258, 249, 305, 146, 76, 99, 326, 265, 274, 94] train_new_idx = [153, 273, 144, 269, 161, 133, 192, 157, 234, 176, 6, 135, 139, 238, 250, 145, 103, 60, 93, 81, 201, 245, 167, 179, 98, 12, 27, 212, 187, 10, 15, 247, 279, 87, 76, 166, 119, 11, 183, 136, 97, 209, 233, 262, 159, 20, 18, 211, 46, 265, 0, 170, 8, 106, 68, 78, 89, 21, 240, 210, 216, 160, 235, 17, 271, 24, 107, 130, 116, 129, 71, 147, 101, 77, 83, 5, 100, 67, 19, 158, 172, 174, 203, 40, 168, 274, 104, 64, 70, 189, 91, 127, 50, 109, 88, 94, 110, 222, 123, 193, 3, 39, 215, 128, 33, 186, 23, 82, 246, 267, 72, 36, 231, 65, 131, 154, 241, 126, 224, 53, 169, 52, 257, 253, 206, 199, 28, 227, 84, 30, 114, 146, 155, 223, 45, 277, 248, 251, 74, 25, 184, 204, 200, 134, 85, 228, 111, 177, 117, 56, 16, 57, 278, 181, 102, 188, 132, 175, 140, 141, 202, 152, 59, 171, 205, 143, 190, 62, 263, 122, 258, 226, 105, 148, 198, 239, 49, 92, 137, 1, 260, 9, 236, 47, 69, 138, 261, 54, 120, 58, 26, 173, 112, 219, 197, 156, 51, 191, 259, 254, 182, 4, 142, 194, 124, 151, 32, 229, 268, 66, 115, 118, 255, 178, 163, 75, 270, 37, 2, 213, 249, 35, 272, 275, 242, 80, 149, 38, 208, 232, 90, 22, 243, 63, 99, 225, 14, 43, 44, 196, 218, 162, 214, 256, 180, 195, 48, 164, 237, 31, 230, 217] valid_idx = [276, 95, 79, 7, 29, 165, 221, 150, 266, 73, 34, 86, 13, 264, 220, 244, 55, 185, 252, 113, 96, 207, 41, 125, 42, 61, 121, 108] total_length = 416 batch[0].size() = torch.Size([16, 3, 384, 384]) batch[0].size() = torch.Size([12, 3, 384, 384]) display images . ValueError Traceback (most recent call last) &lt;ipython-input-1-93c234046ca2&gt; in &lt;cell line: 195&gt;() 194 no_of_image_to_display = 10 195 for idx in np.arange(no_of_image_to_display): --&gt; 196 ax = fig.add_subplot(2, no_of_image_to_display/2, idx+1, xticks=[], yticks=[]) 197 imshow(images[idx]) 198 ax.set_title(classes[labels[idx]]) /usr/local/lib/python3.10/dist-packages/matplotlib/figure.py in add_subplot(self, *args, **kwargs) 755 projection_class, pkw = self._process_projection_requirements( 756 *args, **kwargs) --&gt; 757 ax = projection_class(self, *args, **pkw) 758 key = (projection_class, pkw) 759 return self._add_axes_internal(ax, key) /usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py in __init__(self, fig, facecolor, frameon, sharex, sharey, label, xscale, yscale, box_aspect, *args, **kwargs) 642 else: 643 self._position = self._originalPosition = mtransforms.Bbox.unit() --&gt; 644 subplotspec = SubplotSpec._from_subplot_args(fig, args) 645 if self._position.width &lt; 0 or self._position.height &lt; 0: 646 raise ValueError(&#39;Width and height specified must be non-negative&#39;) /usr/local/lib/python3.10/dist-packages/matplotlib/gridspec.py in _from_subplot_args(figure, args) 585 raise _api.nargs_error(&#34;subplot&#34;, takes=&#34;1 or 3&#34;, given=len(args)) 586 --&gt; 587 gs = GridSpec._check_gridspec_exists(figure, rows, cols) 588 if gs is None: 589 gs = GridSpec(rows, cols, figure=figure) /usr/local/lib/python3.10/dist-packages/matplotlib/gridspec.py in _check_gridspec_exists(figure, nrows, ncols) 224 return gs 225 # else gridspec not found: --&gt; 226 return GridSpec(nrows, ncols, figure=figure) 227 228 def __getitem__(self, key): /usr/local/lib/python3.10/dist-packages/matplotlib/gridspec.py in __init__(self, nrows, ncols, figure, left, bottom, right, top, wspace, hspace, width_ratios, height_ratios) 377 self.figure = figure 378 --&gt; 379 super().__init__(nrows, ncols, 380 width_ratios=width_ratios, 381 height_ratios=height_ratios) /usr/local/lib/python3.10/dist-packages/matplotlib/gridspec.py in __init__(self, nrows, ncols, height_ratios, width_ratios) 50 f&#34;Number of rows must be a positive integer, not {nrows!r}&#34;) 51 if not isinstance(ncols, Integral) or ncols &lt;= 0: &gt; 52 raise ValueError( 53 f&#34;Number of columns must be a positive integer, not {ncols!r}&#34;) 54 self._nrows, self._ncols = nrows, ncols ValueError: Number of columns must be a positive integer, not 5.0 . &lt;Figure size 1000x400 with 0 Axes&gt; .",
            "url": "https://rohitd3.github.io/manyFacesML/python/2023/05/20/facesIdentify.html",
            "relUrl": "/python/2023/05/20/facesIdentify.html",
            "date": " • May 20, 2023"
        }
        
    
  

  
  

  
  

  

  
  

  

  
  

  
  

  
  

  
  

  
      ,"page9": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://rohitd3.github.io/manyFacesML/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}
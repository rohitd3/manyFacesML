<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>What is pytorch? | Faces ML</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="What is pytorch?" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Fastpages" />
<meta property="og:description" content="Fastpages" />
<link rel="canonical" href="https://rohitd3.github.io/manyFacesML/2023/05/23/CNN_faces.html" />
<meta property="og:url" content="https://rohitd3.github.io/manyFacesML/2023/05/23/CNN_faces.html" />
<meta property="og:site_name" content="Faces ML" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-05-23T00:00:00-05:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="What is pytorch?" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-05-23T00:00:00-05:00","datePublished":"2023-05-23T00:00:00-05:00","description":"Fastpages","headline":"What is pytorch?","mainEntityOfPage":{"@type":"WebPage","@id":"https://rohitd3.github.io/manyFacesML/2023/05/23/CNN_faces.html"},"url":"https://rohitd3.github.io/manyFacesML/2023/05/23/CNN_faces.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/manyFacesML/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://rohitd3.github.io/manyFacesML/feed.xml" title="Faces ML" /><link rel="shortcut icon" type="image/x-icon" href="/manyFacesML/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/manyFacesML/">Faces ML</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/manyFacesML/search/">Search</a><a class="page-link" href="/manyFacesML/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">What is pytorch?</h1><p class="post-meta post-meta-title"><time class="dt-published" datetime="2023-05-23T00:00:00-05:00" itemprop="datePublished">
        May 23, 2023
      </time>
       â€¢ <span class="read-time" title="Estimated read time">
    
    
      20 min read
    
</span></p>

    

    
      
        <div class="pb-5 d-flex flex-justify-center">
          <div class="px-2">

    <a href="https://github.com/rohitd3/manyFacesML/tree/master/_notebooks/CNN_faces.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/manyFacesML/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/rohitd3/manyFacesML/master?filepath=_notebooks%2FCNN_faces.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/manyFacesML/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/rohitd3/manyFacesML/blob/master/_notebooks/CNN_faces.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/manyFacesML/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
          <div class="px-2">
  <a href="https://deepnote.com/launch?url=https%3A%2F%2Fgithub.com%2Frohitd3%2FmanyFacesML%2Fblob%2Fmaster%2F_notebooks%2FCNN_faces.ipynb" target="_blank">
      <img class="notebook-badge-image" src="/manyFacesML/assets/badges/deepnote.svg" alt="Launch in Deepnote"/>
  </a>
</div>

        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/CNN_faces.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">torch</span> <span class="n">torchvision</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">torchviz</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="o">--</span><span class="n">upgrade</span> <span class="n">torch</span> <span class="n">torchvision</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)
Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)
Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)
Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)
Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)
Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)
Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)
Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)
Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-&gt;torch) (3.25.2)
Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-&gt;torch) (16.0.5)
Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)
Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)
Requirement already satisfied: pillow!=8.3.*,&gt;=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0)
Requirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-&gt;torch) (2.1.2)
Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;torchvision) (1.26.15)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;torchvision) (2022.12.7)
Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;torchvision) (2.0.12)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;torchvision) (3.4)
Requirement already satisfied: mpmath&gt;=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-&gt;torch) (1.3.0)
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Requirement already satisfied: torchviz in /usr/local/lib/python3.10/dist-packages (0.0.2)
Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchviz) (2.0.1+cu118)
Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from torchviz) (0.20.1)
Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch-&gt;torchviz) (3.12.0)
Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch-&gt;torchviz) (4.5.0)
Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch-&gt;torchviz) (1.11.1)
Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch-&gt;torchviz) (3.1)
Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;torchviz) (3.1.2)
Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;torchviz) (2.0.0)
Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-&gt;torch-&gt;torchviz) (3.25.2)
Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-&gt;torch-&gt;torchviz) (16.0.5)
Requirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-&gt;torch-&gt;torchviz) (2.1.2)
Requirement already satisfied: mpmath&gt;=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-&gt;torch-&gt;torchviz) (1.3.0)
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)
Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)
Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)
Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)
Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)
Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)
Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)
Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)
Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-&gt;torch) (3.25.2)
Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-&gt;torch) (16.0.5)
Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)
Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)
Requirement already satisfied: pillow!=8.3.*,&gt;=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0)
Requirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-&gt;torch) (2.1.2)
Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;torchvision) (1.26.15)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;torchvision) (2022.12.7)
Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;torchvision) (2.0.12)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;torchvision) (3.4)
Requirement already satisfied: mpmath&gt;=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-&gt;torch) (1.3.0)
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>

<span class="k">def</span> <span class="nf">restart_runtime</span><span class="p">():</span>
  <span class="n">os</span><span class="o">.</span><span class="n">kill</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getpid</span><span class="p">(),</span> <span class="mi">9</span><span class="p">)</span>

<span class="n">restart_runtime</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">data_directory_face</span> <span class="o">=</span> <span class="s1">&#39;/content/gdrive/MyDrive/DNN_ML/face&#39;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">google.colab</span> <span class="kn">import</span> <span class="n">drive</span>
<span class="kn">from</span> <span class="nn">google.colab</span> <span class="kn">import</span> <span class="n">files</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>

<span class="n">drive</span><span class="o">.</span><span class="n">mount</span><span class="p">(</span><span class="s1">&#39;/content/gdrive&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Mounted at /content/gdrive
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">data_directory_face</span> <span class="o">=</span> <span class="s1">&#39;/content/gdrive/MyDrive/DNN_ML/face&#39;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="c1"># Keep the Image width, height a multiple of 4.</span>
<span class="c1">#This will ensure after Conv2D with 5X5 filter, and MaxPool(2,2) TWICE,</span>
<span class="c1"># the values height2, width2 are still integers</span>
<span class="n">ImageWidth</span><span class="o">=</span><span class="mi">384</span>
<span class="n">ImageHeight</span><span class="o">=</span><span class="mi">384</span>

<span class="c1">#the most common choices for convolution filter kernel sizes appear to be square shape of sizes 3X3, 5X5</span>
<span class="c1">#smaller sized kernel allows for more granular information. Here 5X5 is used.</span>
<span class="c1">#Maxpool is needed when the image is larger. It keeps the item with the maximum value.</span>

<span class="n">convKernelSize1</span> <span class="o">=</span><span class="mi">5</span>
<span class="n">convKernelSize2</span> <span class="o">=</span><span class="mi">5</span>
<span class="n">maxpoolKernelSize</span> <span class="o">=</span> <span class="mi">2</span>

<span class="c1">#conv1 Input Channel is default 3 for R, G, B channels directly from the colored Image</span>
<span class="n">convOutputChannel1</span> <span class="o">=</span> <span class="mi">16</span>
<span class="c1">#convInputChannel2 is the same as the convOutputChannel1</span>
<span class="n">convOutputChannel2</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">linearOut1</span> <span class="o">=</span> <span class="mi">256</span>
<span class="n">linearOut2</span> <span class="o">=</span> <span class="mi">84</span>

<span class="n">dropOutValue</span> <span class="o">=</span> <span class="mf">0.2</span>

<span class="c1"># for the first convolution and max pool</span>
<span class="n">height1</span><span class="o">=</span><span class="nb">int</span><span class="p">((</span><span class="n">ImageHeight</span> <span class="o">-</span> <span class="n">convKernelSize1</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="n">maxpoolKernelSize</span><span class="p">)</span> 
<span class="n">width1</span><span class="o">=</span><span class="nb">int</span><span class="p">((</span><span class="n">ImageWidth</span> <span class="o">-</span> <span class="n">convKernelSize1</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="n">maxpoolKernelSize</span><span class="p">)</span>

<span class="c1"># for the second convolution and max pool</span>
<span class="n">height2</span><span class="o">=</span><span class="nb">int</span><span class="p">((</span><span class="n">height1</span> <span class="o">-</span> <span class="n">convKernelSize2</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="n">maxpoolKernelSize</span><span class="p">)</span> 
<span class="n">width2</span><span class="o">=</span><span class="nb">int</span><span class="p">((</span><span class="n">width1</span> <span class="o">-</span> <span class="n">convKernelSize2</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="n">maxpoolKernelSize</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot; ImageWidth = &quot;</span><span class="p">,</span> <span class="n">ImageWidth</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot; ImageHeight = &quot;</span><span class="p">,</span> <span class="n">ImageHeight</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot; width1 = &quot;</span><span class="p">,</span> <span class="n">width1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot; height1 = &quot;</span><span class="p">,</span> <span class="n">height1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot; width2 = &quot;</span><span class="p">,</span> <span class="n">width2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot; height2 = &quot;</span><span class="p">,</span> <span class="n">height2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre> ImageWidth =  384
 ImageHeight =  384
 width1 =  190
 height1 =  190
 width2 =  93
 height2 =  93
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>
<span class="c1"># percentage of training set to use as validation</span>
<span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.3</span>
<span class="n">valid_size</span> <span class="o">=</span> <span class="mf">0.1</span>

<span class="c1"># Preprocessing steps</span>
<span class="c1"># Horizontal Flip, Random Rotation, convert image array into PyTorch and normalize</span>
<span class="n">train_transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">RandomRotation</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">ImageWidth</span><span class="p">,</span><span class="n">ImageHeight</span><span class="p">)),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">))</span> <span class="c1"># need to keep these transforms, at least do resize all images to same size and co</span>
    <span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">ImageFolder</span><span class="p">(</span><span class="n">data_directory_face</span><span class="p">,</span><span class="n">transform</span><span class="o">=</span><span class="n">train_transform</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The data needs to be split in Train, Test and validation set before training.</p>
<ul>
<li>Train set will be used to train the model.</li>
<li>Validation set will be used for validating the model after each epoch. </li>
<li>Test set will be used to evaluate the model once it is trained.</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">num_data</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;num_data = &quot;</span><span class="p">,</span> <span class="n">num_data</span><span class="p">)</span>

<span class="n">indices_data</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">num_data</span><span class="p">))</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">indices_data</span><span class="p">)</span>

<span class="c1">#For test and training</span>

<span class="n">split_tt</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">test_size</span> <span class="o">*</span> <span class="n">num_data</span><span class="p">))</span>

<span class="c1"># numpy.floor function operates element-wise on the input array, </span>
<span class="c1"># returning a new array with the same shape as the input. </span>
<span class="c1"># It rounds down each element of the input array to the nearest </span>
<span class="c1"># integer that is less than or equal to that element</span>

<span class="n">train_idx</span><span class="p">,</span> <span class="n">test_idx</span> <span class="o">=</span> <span class="n">indices_data</span><span class="p">[</span><span class="n">split_tt</span><span class="p">:],</span> <span class="n">indices_data</span><span class="p">[:</span><span class="n">split_tt</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> train_idx = &quot;</span><span class="p">,</span> <span class="n">train_idx</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> test_idx = &quot;</span><span class="p">,</span> <span class="n">test_idx</span><span class="p">)</span>

<span class="c1">#From training separate data For validation (for each epoch)</span>
<span class="n">num_train</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_idx</span><span class="p">)</span>
<span class="n">indices_train</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">num_train</span><span class="p">))</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">indices_train</span><span class="p">)</span>
<span class="n">split_tv</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">valid_size</span> <span class="o">*</span> <span class="n">num_train</span><span class="p">))</span>
<span class="n">train_new_idx</span><span class="p">,</span> <span class="n">valid_idx</span> <span class="o">=</span> <span class="n">indices_train</span><span class="p">[</span><span class="n">split_tv</span><span class="p">:],</span><span class="n">indices_train</span><span class="p">[:</span><span class="n">split_tv</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> train_new_idx = &quot;</span><span class="p">,</span> <span class="n">train_new_idx</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> valid_idx = &quot;</span><span class="p">,</span> <span class="n">valid_idx</span><span class="p">)</span>

<span class="c1"># define samplers for obtaining training and validation batches</span>
<span class="n">train_sampler</span> <span class="o">=</span> <span class="n">SubsetRandomSampler</span><span class="p">(</span><span class="n">train_new_idx</span><span class="p">)</span>
<span class="n">valid_sampler</span> <span class="o">=</span> <span class="n">SubsetRandomSampler</span><span class="p">(</span><span class="n">valid_idx</span><span class="p">)</span>
<span class="n">test_sampler</span> <span class="o">=</span> <span class="n">SubsetRandomSampler</span><span class="p">(</span><span class="n">test_idx</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>num_data =  400

 train_idx =  [327, 183, 171, 96, 7, 167, 379, 105, 236, 40, 339, 180, 189, 255, 120, 58, 302, 344, 276, 141, 215, 229, 103, 203, 313, 60, 224, 69, 73, 28, 375, 15, 247, 20, 230, 155, 25, 187, 243, 226, 118, 249, 383, 350, 377, 1, 13, 57, 237, 239, 235, 51, 131, 115, 86, 186, 316, 382, 309, 394, 271, 354, 304, 16, 365, 305, 52, 98, 100, 55, 84, 80, 88, 185, 280, 284, 90, 143, 328, 217, 110, 288, 374, 258, 0, 49, 47, 282, 210, 347, 97, 14, 146, 290, 125, 222, 368, 85, 194, 228, 72, 107, 67, 363, 182, 334, 42, 124, 298, 152, 209, 166, 323, 318, 232, 381, 59, 306, 397, 346, 380, 360, 77, 196, 176, 244, 211, 10, 181, 338, 256, 178, 387, 307, 193, 45, 351, 179, 63, 225, 35, 353, 61, 262, 385, 201, 398, 109, 311, 301, 285, 89, 3, 144, 293, 156, 75, 348, 219, 333, 366, 79, 299, 24, 34, 376, 221, 263, 372, 364, 159, 190, 204, 355, 340, 371, 62, 160, 33, 253, 4, 22, 9, 273, 30, 384, 8, 295, 134, 267, 18, 154, 342, 317, 321, 308, 242, 223, 112, 252, 238, 245, 289, 76, 199, 369, 195, 151, 248, 319, 343, 165, 121, 128, 279, 113, 297, 157, 87, 322, 92, 102, 216, 74, 150, 234, 325, 268, 241, 330, 148, 281, 170, 362, 32, 218, 114, 233, 214, 393, 188, 104, 349, 153, 251, 147, 132, 95, 2, 99, 231, 312, 310, 116, 46, 117, 300, 44, 39, 359, 212, 395, 27, 50, 261, 101, 174, 68, 391, 106, 388, 130, 303, 296, 213, 345, 259, 177, 149, 172]

 test_idx =  [335, 269, 37, 66, 133, 257, 314, 396, 21, 275, 336, 145, 370, 36, 41, 390, 220, 392, 119, 337, 17, 198, 83, 70, 137, 162, 329, 315, 205, 265, 331, 197, 332, 65, 191, 82, 361, 184, 254, 286, 163, 94, 111, 287, 260, 93, 138, 358, 71, 278, 126, 291, 208, 78, 139, 373, 43, 6, 135, 142, 192, 81, 272, 352, 250, 227, 140, 108, 324, 168, 11, 202, 386, 266, 91, 292, 207, 246, 53, 38, 56, 294, 161, 127, 341, 357, 54, 122, 173, 29, 129, 283, 164, 200, 356, 64, 31, 264, 19, 277, 206, 12, 378, 399, 240, 26, 326, 5, 175, 169, 123, 158, 367, 389, 23, 274, 136, 270, 48, 320]

 train_new_idx =  [27, 184, 45, 155, 253, 224, 60, 38, 210, 51, 101, 114, 228, 197, 66, 88, 132, 134, 245, 70, 26, 9, 256, 6, 83, 96, 15, 99, 78, 8, 29, 130, 79, 162, 274, 202, 154, 222, 231, 46, 193, 242, 180, 116, 263, 115, 212, 135, 213, 239, 269, 144, 247, 61, 216, 181, 138, 271, 150, 173, 221, 90, 227, 4, 262, 182, 112, 105, 74, 226, 204, 118, 62, 166, 240, 149, 31, 24, 254, 163, 236, 175, 148, 207, 174, 246, 95, 80, 142, 13, 36, 123, 252, 54, 117, 196, 108, 53, 100, 244, 50, 237, 48, 260, 35, 220, 267, 129, 32, 257, 232, 157, 97, 225, 223, 49, 84, 86, 199, 23, 5, 187, 2, 219, 268, 111, 110, 87, 183, 198, 72, 230, 47, 258, 122, 119, 161, 102, 272, 205, 11, 214, 133, 215, 77, 151, 264, 124, 200, 64, 278, 158, 137, 276, 25, 113, 176, 41, 172, 92, 22, 145, 12, 277, 188, 0, 44, 42, 164, 208, 34, 141, 251, 68, 194, 1, 211, 85, 143, 243, 209, 203, 63, 81, 106, 93, 171, 67, 233, 186, 10, 71, 160, 91, 241, 190, 21, 131, 279, 28, 7, 56, 43, 18, 192, 82, 250, 167, 19, 169, 147, 261, 191, 136, 103, 65, 58, 178, 98, 206, 37, 140, 270, 75, 275, 179, 195, 20, 234, 259, 89, 16, 107, 255, 126, 73, 265, 76, 17, 127, 189, 165, 156, 248, 52, 153, 3, 94, 249, 125, 69, 229]

 valid_idx =  [218, 30, 235, 33, 217, 120, 177, 159, 139, 185, 266, 55, 40, 128, 39, 170, 238, 201, 14, 146, 59, 109, 273, 121, 168, 57, 104, 152]
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="c1"># train_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, sampler=train_sampler, num_workers=1, transform=train_transform)</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="n">train_sampler</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># only running the data augmentation on the training data, double check if works</span>
<span class="n">valid_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="n">valid_sampler</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">sampler</span> <span class="o">=</span> <span class="n">test_sampler</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># variable representing classes of the images</span>
<span class="n">classes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># labeling either 0 (negative) or 1 (positive)</span>

<span class="n">total_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_loader</span><span class="p">)</span><span class="o">*</span><span class="n">batch_size</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">valid_loader</span><span class="p">)</span><span class="o">*</span><span class="n">batch_size</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span><span class="o">*</span><span class="n">batch_size</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;total_length = &quot;</span><span class="p">,</span> <span class="n">total_length</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>total_length =  416
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">valid_loader</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;batch[0].size() = &quot;</span><span class="p">,</span> <span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>batch[0].size() =  torch.Size([16, 3, 384, 384])
batch[0].size() =  torch.Size([12, 3, 384, 384])
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>

<span class="c1"># helper function to un-normalize and display an image</span>
<span class="k">def</span> <span class="nf">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">):</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">img</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">+</span> <span class="mf">0.5</span>  <span class="c1"># unnormalize</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)))</span>  <span class="c1"># convert from Tensor image</span>
    
<span class="c1"># obtain one batch of training images</span>
<span class="n">dataiter</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>
<span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">dataiter</span><span class="p">)</span>
<span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="c1"># convert images to numpy for display</span>

<span class="c1"># plot the images in the batch, along with the corresponding labels</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea ">
<pre>&lt;Figure size 1000x400 with 0 Axes&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">num_of_image_to_display</span> <span class="o">=</span> <span class="mi">16</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="n">num_of_image_to_display</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

<span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">num_of_image_to_display</span><span class="p">):</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">num_of_image_to_display</span><span class="o">/</span><span class="mi">2</span><span class="p">),</span> <span class="n">idx</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">xticks</span><span class="o">=</span><span class="p">[],</span> <span class="n">yticks</span><span class="o">=</span><span class="p">[])</span>
    <span class="n">imshow</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">classes</span><span class="p">[</span><span class="n">labels</span><span class="p">[</span><span class="n">idx</span><span class="p">]])</span>

<span class="n">display</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">())</span>
<span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">NameError</span>                                 Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-1-61107625c75e&gt;</span> in <span class="ansi-cyan-fg">&lt;cell line: 3&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">      1</span> num_of_image_to_display <span class="ansi-blue-fg">=</span> <span class="ansi-cyan-fg">16</span>
<span class="ansi-green-intense-fg ansi-bold">      2</span> 
<span class="ansi-green-fg">----&gt; 3</span><span class="ansi-red-fg"> </span>fig <span class="ansi-blue-fg">=</span> plt<span class="ansi-blue-fg">.</span>figure<span class="ansi-blue-fg">(</span>figsize<span class="ansi-blue-fg">=</span><span class="ansi-blue-fg">(</span>num_of_image_to_display<span class="ansi-blue-fg">,</span> <span class="ansi-cyan-fg">4</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">      4</span> 
<span class="ansi-green-intense-fg ansi-bold">      5</span> <span class="ansi-green-fg">for</span> idx <span class="ansi-green-fg">in</span> np<span class="ansi-blue-fg">.</span>arange<span class="ansi-blue-fg">(</span>num_of_image_to_display<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>

<span class="ansi-red-fg">NameError</span>: name &#39;plt&#39; is not defined</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="kn">from</span> <span class="nn">torch.utils.data.sampler</span> <span class="kn">import</span> <span class="n">SubsetRandomSampler</span>


<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">import</span> <span class="nn">torch.utils.data</span> <span class="k">as</span> <span class="nn">data</span>
<span class="kn">import</span> <span class="nn">torchvision.models</span> <span class="k">as</span> <span class="nn">models</span>
<span class="kn">from</span> <span class="nn">torch.autograd</span> <span class="kn">import</span> <span class="n">Variable</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="n">train_on_gpu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;train_on_gpu = &quot;</span><span class="p">,</span> <span class="n">train_on_gpu</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        
        <span class="c1"># define the two convolutional operations</span>
        <span class="c1"># conv1 Input Channel =3 for the R, G, B channels directly from the Image</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">convOutputChannel1</span><span class="p">,</span> <span class="n">convKernelSize1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">convOutputChannel1</span><span class="p">,</span> <span class="n">convOutputChannel2</span><span class="p">,</span> <span class="n">convKernelSize2</span><span class="p">)</span>

        <span class="c1"># define the max pool operation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">maxpoolKernelSize</span><span class="p">,</span> <span class="n">maxpoolKernelSize</span><span class="p">)</span>        
        
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropOutValue</span><span class="p">)</span>
         
        <span class="c1"># define the Linear (fully connected) operations </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">convOutputChannel2</span><span class="o">*</span> <span class="n">height2</span> <span class="o">*</span> <span class="n">width2</span><span class="p">,</span> <span class="n">linearOut1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">linearOut1</span><span class="p">,</span> <span class="n">linearOut2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">linearOut2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LogSoftmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
  
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># add sequence of convolutional, relu and max pooling layers</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1"># the linearization needs to start with = # of output channels * height2 * width2</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">convOutputChannel2</span> <span class="o">*</span> <span class="n">height2</span> <span class="o">*</span> <span class="n">width2</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>train_on_gpu =  True
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Training-the-Model">Training the Model<a class="anchor-link" href="#Training-the-Model"> </a></h1><p>Finally comes the training part. Here you need to decide two crucial things: Loss function and optimizer. 
 There are various choices like SGD, Adam, etc.. for the optimizer.
 used Cross-Entropy loss, which is a popular choice in the case of classification problems.
 should also set a learning rate, which decides how fast your model learns.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;++++++++++++ print the model ++++++++&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;+++++++++++++++++++++++++++++++++++++&quot;</span><span class="p">)</span>

<span class="c1"># move tensors to GPU if CUDA is available</span>
<span class="k">if</span> <span class="n">train_on_gpu</span><span class="p">:</span>
    <span class="n">model</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>++++++++++++ print the model ++++++++
Net(
  (conv1): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (dropout): Dropout(p=0.2, inplace=False)
  (fc1): Linear(in_features=276768, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=84, bias=True)
  (fc3): Linear(in_features=84, out_features=2, bias=True)
  (softmax): LogSoftmax(dim=1)
)
+++++++++++++++++++++++++++++++++++++
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>

<span class="c1"># specify loss function</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.003</span>

<span class="c1"># --------------- test with Stochastic gradient descent optimizer -------------------</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span> <span class="o">=</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span> <span class="mf">0.9</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">5</span> <span class="c1"># you may increase this number to train a final model</span>

<span class="n">valid_loss_min</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">Inf</span> <span class="c1"># track change in validation loss</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>make_loss_graph function takes in data_list_val and data_list_train as input, which are lists of loss values for validation and training data. It plots these values on a graph and displays it.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">make_loss_graph</span><span class="p">(</span><span class="n">data_list_val</span><span class="p">,</span> <span class="n">data_list_train</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Training and Validation Loss per Epoch&quot;</span><span class="p">)</span>

    <span class="n">val_label</span> <span class="o">=</span> <span class="s2">&quot;Validation Loss &quot;</span> 
    <span class="n">train_label</span> <span class="o">=</span> <span class="s2">&quot;Training Loss &quot;</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_list_val</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_list_train</span><span class="p">)</span> <span class="c1">##makes sure the lengths of each are the same, will give error if not</span>
    <span class="n">length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_list_train</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">data_list_val</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">val_label</span><span class="p">)</span> <span class="c1">##validation data</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">data_list_train</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">train_label</span><span class="p">)</span> <span class="c1">##training data</span>
    <span class="c1">#plt.xlim((epoch_skip, length))</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epochs&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>

    <span class="n">display</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">())</span> <span class="c1">##displays plot</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Underfitting-and-overfitting">Underfitting and overfitting<a class="anchor-link" href="#Underfitting-and-overfitting"> </a></h1><p>Reasons for Underfitting:</p>

<pre><code>High bias and low variance 
The size of the training dataset used is not enough.
The model is too simple.
Training data is not cleaned and also contains noise in it.

</code></pre>
<p>Techniques to reduce underfitting:</p>

<pre><code>Increase model complexity
Increase the number of features, performing feature engineering
Remove noise from the data.
Increase the number of epochs or increase the duration of training to get better results.

</code></pre>
<p><a href="https://www.geeksforgeeks.org/underfitting-and-overfitting-in-machine-learning/#">https://www.geeksforgeeks.org/underfitting-and-overfitting-in-machine-learning/#</a></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">list_val_loss_all_epoch</span> <span class="o">=</span><span class="p">[]</span> 
<span class="n">list_train_loss_all_epoch</span> <span class="o">=</span><span class="p">[]</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_epochs</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;####### EPOCH &#39;</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
    <span class="c1"># keep track of training and validation loss</span>
    <span class="n">train_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">valid_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    
    <span class="n">train_items</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">valid_items</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="c1">###################</span>
    <span class="c1"># train the model #</span>
    <span class="c1">###################</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39; len(train_loader.dataset) = &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
        <span class="c1"># move tensors to GPU if CUDA is available</span>
        <span class="k">if</span> <span class="n">train_on_gpu</span><span class="p">:</span>
            <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">cuda</span><span class="p">(),</span> <span class="n">target</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
        <span class="c1"># clear the gradients of all optimized variables</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="c1"># forward pass: compute predicted outputs by passing inputs to the model</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="c1"># calculate the batch loss</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
        <span class="c1"># backward pass: compute gradient of the loss with respect to model parameters</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="c1"># perform a single optimization step (parameter update)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="c1"># update training loss</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;   train loss item = &#39;</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="o">*</span><span class="n">data</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
        <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="o">*</span><span class="n">data</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">train_items</span> <span class="o">+=</span><span class="mi">1</span>
        
    <span class="c1">######################    </span>
    <span class="c1"># validate or evaluate the model #</span>
    <span class="c1"># To evaluate the model, it should be changed from model.train() to model.eval()</span>
    <span class="c1">######################</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39; len(valid_loader.dataset) = &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">valid_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">valid_loader</span><span class="p">:</span>
        <span class="c1"># move tensors to GPU if CUDA is available</span>
        <span class="k">if</span> <span class="n">train_on_gpu</span><span class="p">:</span>
            <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">cuda</span><span class="p">(),</span> <span class="n">target</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
        <span class="c1"># forward pass: compute predicted outputs by passing inputs to the model</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="c1"># calculate the batch loss</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
        <span class="c1"># update average validation loss </span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;   valid loss item = &#39;</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="o">*</span><span class="n">data</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
        <span class="n">valid_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="o">*</span><span class="n">data</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">valid_items</span> <span class="o">+=</span><span class="mi">1</span>
    
    <span class="c1"># calculate average losses</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1"> train_loss = &#39;</span><span class="p">,</span> <span class="n">train_loss</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39; valid_loss = &#39;</span><span class="p">,</span> <span class="n">valid_loss</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1"> train_items = &#39;</span><span class="p">,</span> <span class="n">train_items</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39; valid_items = &#39;</span><span class="p">,</span> <span class="n">valid_items</span><span class="p">)</span>
    <span class="c1">#train_loss = train_loss/len(train_loader.dataset) # incorrect: this was averaging over 500 (the total amount of images available)</span>
    <span class="c1">#valid_loss = valid_loss/len(valid_loader.dataset)</span>
    <span class="n">train_loss</span> <span class="o">=</span> <span class="n">train_loss</span><span class="o">/</span><span class="n">train_items</span> <span class="c1"># this is averaging correctly</span>
    <span class="n">valid_loss</span> <span class="o">=</span> <span class="n">valid_loss</span><span class="o">/</span><span class="n">valid_items</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1"> average train_loss = &#39;</span><span class="p">,</span> <span class="n">train_loss</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39; average valid_loss = &#39;</span><span class="p">,</span> <span class="n">valid_loss</span><span class="p">)</span>

    <span class="n">list_val_loss_all_epoch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">valid_loss</span><span class="p">)</span>
    <span class="n">list_train_loss_all_epoch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_loss</span><span class="p">)</span>

    <span class="c1"># print training/validation statistics </span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch: </span><span class="si">{}</span><span class="s1"> </span><span class="se">\t</span><span class="s1"> Average Training Loss: </span><span class="si">{:.6f}</span><span class="s1"> </span><span class="se">\t</span><span class="s1"> Average Validation Loss: </span><span class="si">{:.6f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">epoch</span><span class="p">,</span> <span class="n">train_loss</span><span class="p">,</span> <span class="n">valid_loss</span><span class="p">))</span>


    <span class="c1"># save model if validation loss has decreased</span>
    <span class="k">if</span> <span class="n">valid_loss</span> <span class="o">&lt;=</span> <span class="n">valid_loss_min</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Validation loss decreased (</span><span class="si">{:.6f}</span><span class="s1"> --&gt; </span><span class="si">{:.6f}</span><span class="s1">).  Saving model ...&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">valid_loss_min</span><span class="p">,</span>
        <span class="n">valid_loss</span><span class="p">))</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">&#39;model_cifar.pt&#39;</span><span class="p">)</span>
        <span class="n">valid_loss_min</span> <span class="o">=</span> <span class="n">valid_loss</span>

<span class="n">make_loss_graph</span><span class="p">(</span><span class="n">list_val_loss_all_epoch</span><span class="p">,</span> <span class="n">list_train_loss_all_epoch</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>####### EPOCH  1
 len(train_loader.dataset) =  400
   train loss item =  0.024645444005727768
   train loss item =  0.32031652331352234
   train loss item =  0.05283474177122116
   train loss item =  0.9114115238189697
   train loss item =  0.04939626529812813
   train loss item =  0.03176403045654297
   train loss item =  0.02037661150097847
   train loss item =  0.11796353757381439
   train loss item =  0.4087546467781067
   train loss item =  0.12971322238445282
   train loss item =  0.2309323251247406
   train loss item =  0.17112958431243896
   train loss item =  0.00805441290140152
   train loss item =  0.7278347015380859
   train loss item =  0.03808647766709328
   train loss item =  0.001081527181668207
 len(valid_loader.dataset) =  400
   valid loss item =  0.3364920914173126
   valid loss item =  0.7835705280303955

 train_loss =  3.244295575626893
 valid_loss =  1.1200626194477081

 train_items =  16.0
 valid_items =  2.0

 average train_loss =  0.2027684734766808
 average valid_loss =  0.5600313097238541
Epoch: 1 	 Average Training Loss: 0.202768 	 Average Validation Loss: 0.560031
Validation loss decreased (1.058500 --&gt; 0.560031).  Saving model ...
####### EPOCH  2
 len(train_loader.dataset) =  400
   train loss item =  0.017503857612609863
   train loss item =  0.012020493857562542
   train loss item =  1.2742114067077637
   train loss item =  0.02505093812942505
   train loss item =  0.03209812566637993
   train loss item =  0.16146953403949738
   train loss item =  0.1393091380596161
   train loss item =  1.8395599126815796
   train loss item =  6.752047061920166
   train loss item =  0.016535572707653046
   train loss item =  0.012823164463043213
   train loss item =  0.04886973649263382
   train loss item =  0.11911410838365555
   train loss item =  0.8541668057441711
   train loss item =  8.914411544799805
   train loss item =  0.007184454007074237
 len(valid_loader.dataset) =  400
   valid loss item =  5.69299840927124
   valid loss item =  0.004451676271855831

 train_loss =  20.226375855272636
 valid_loss =  5.697450085543096

 train_items =  16.0
 valid_items =  2.0

 average train_loss =  1.2641484909545397
 average valid_loss =  2.848725042771548
Epoch: 2 	 Average Training Loss: 1.264148 	 Average Validation Loss: 2.848725
####### EPOCH  3
 len(train_loader.dataset) =  400
   train loss item =  0.28011396527290344
   train loss item =  0.23054836690425873
   train loss item =  0.05393335595726967
   train loss item =  1.2450270652770996
   train loss item =  0.08126480132341385
   train loss item =  0.5129839181900024
   train loss item =  0.4966256022453308
   train loss item =  0.08642233908176422
   train loss item =  1.2715575695037842
   train loss item =  0.1827414333820343
   train loss item =  0.20200985670089722
   train loss item =  0.2556696832180023
   train loss item =  0.10684928297996521
   train loss item =  0.11533006280660629
   train loss item =  0.12136797606945038
   train loss item =  0.1404786966741085
 len(valid_loader.dataset) =  400
   valid loss item =  0.19773808121681213
   valid loss item =  0.9970040023326874

 train_loss =  5.382923975586891
 valid_loss =  1.1947420835494995

 train_items =  16.0
 valid_items =  2.0

 average train_loss =  0.3364327484741807
 average valid_loss =  0.5973710417747498
Epoch: 3 	 Average Training Loss: 0.336433 	 Average Validation Loss: 0.597371
####### EPOCH  4
 len(train_loader.dataset) =  400
   train loss item =  0.20712696015834808
   train loss item =  0.07195495814085007
   train loss item =  0.14663034677505493
   train loss item =  0.1379862129688263
   train loss item =  0.11275184154510498
   train loss item =  0.16099438071250916
   train loss item =  0.08503907173871994
   train loss item =  0.0856439545750618
   train loss item =  0.29068124294281006
   train loss item =  0.017780523747205734
   train loss item =  0.05050569772720337
   train loss item =  0.011246606707572937
   train loss item =  0.0094155790284276
   train loss item =  0.059190504252910614
   train loss item =  0.027335597202181816
   train loss item =  0.02183528244495392
 len(valid_loader.dataset) =  400
   valid loss item =  0.02724332921206951
   valid loss item =  0.4153520464897156

 train_loss =  1.4961187606677413
 valid_loss =  0.4425953757017851

 train_items =  16.0
 valid_items =  2.0

 average train_loss =  0.09350742254173383
 average valid_loss =  0.22129768785089254
Epoch: 4 	 Average Training Loss: 0.093507 	 Average Validation Loss: 0.221298
Validation loss decreased (0.560031 --&gt; 0.221298).  Saving model ...
####### EPOCH  5
 len(train_loader.dataset) =  400
   train loss item =  0.29646751284599304
   train loss item =  0.06760089844465256
   train loss item =  0.07073017954826355
   train loss item =  0.053998708724975586
   train loss item =  0.005736634135246277
   train loss item =  0.0050850375555455685
   train loss item =  0.0208502858877182
   train loss item =  0.246884286403656
   train loss item =  0.015171251259744167
   train loss item =  0.02811436913907528
   train loss item =  0.003049638122320175
   train loss item =  0.001593883614987135
   train loss item =  0.001167911570519209
   train loss item =  0.1199827566742897
   train loss item =  0.02852724678814411
   train loss item =  1.006018728017807
 len(valid_loader.dataset) =  400
   valid loss item =  0.4509490430355072
   valid loss item =  0.032683937810361385

 train_loss =  1.9709793287329376
 valid_loss =  0.4836329808458686

 train_items =  16.0
 valid_items =  2.0

 average train_loss =  0.1231862080458086
 average valid_loss =  0.2418164904229343
Epoch: 5 	 Average Training Loss: 0.123186 	 Average Validation Loss: 0.241816
</pre>
</div>
</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
" />
</div>

</div>

<div class="output_area">



<div class="output_text output_subarea ">
<pre>None</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="c1"># Analysis of the Model</span>
<span class="c1"># plotting loss and accuracy over epochs to see how it changed over training</span>
<span class="c1">######################################################</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> ****************  START TEST ******************* &quot;</span><span class="p">)</span>
<span class="c1"># plot the accuracy</span>
<span class="c1"># confusion matrix</span>
<span class="c1"># dont train for 700 epochs - do for less ~20</span>

<span class="c1"># track test loss</span>
<span class="n">test_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
<span class="n">class_correct</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="mf">0.</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
<span class="n">class_total</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="mf">0.</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">i</span><span class="o">=</span><span class="mi">1</span>
<span class="c1"># iterate over test data</span>
<span class="nb">len</span><span class="p">(</span><span class="n">test_loader</span><span class="p">)</span>
<span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
    <span class="n">i</span><span class="o">=</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">target</span><span class="p">)</span><span class="o">!=</span><span class="n">batch_size</span><span class="p">:</span>
        <span class="k">continue</span>
        
    <span class="c1"># move tensors to GPU if CUDA is available</span>
    <span class="k">if</span> <span class="n">train_on_gpu</span><span class="p">:</span>
        <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">cuda</span><span class="p">(),</span> <span class="n">target</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
    <span class="c1"># forward pass: compute predicted outputs by passing inputs to the model</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="c1"># calculate the batch loss</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
    <span class="c1"># update test loss </span>
    <span class="n">test_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="o">*</span><span class="n">data</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="c1"># convert output probabilities to predicted class</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">pred</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>    
    <span class="c1"># compare predictions to true label</span>
    <span class="n">correct_tensor</span> <span class="o">=</span> <span class="n">pred</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">view_as</span><span class="p">(</span><span class="n">pred</span><span class="p">))</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">correct_tensor</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">train_on_gpu</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">correct_tensor</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
    <span class="c1"># calculate test accuracy for each object class</span>
<span class="c1">#     print(target)</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>       
        <span class="n">label</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">class_correct</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">+=</span> <span class="n">correct</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">class_total</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="c1"># average test loss</span>
<span class="n">test_loss</span> <span class="o">=</span> <span class="n">test_loss</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">test_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test Loss: </span><span class="si">{:.6f}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">test_loss</span><span class="p">))</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">class_total</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test Accuracy of </span><span class="si">%5s</span><span class="s1">: </span><span class="si">%2d%%</span><span class="s1"> (</span><span class="si">%2d</span><span class="s1">/</span><span class="si">%2d</span><span class="s1">)&#39;</span> <span class="o">%</span> <span class="p">(</span>
            <span class="n">classes</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">class_correct</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="n">class_total</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
            <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">class_correct</span><span class="p">[</span><span class="n">i</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">class_total</span><span class="p">[</span><span class="n">i</span><span class="p">])))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test Accuracy of </span><span class="si">%5s</span><span class="s1">: N/A (no training examples)&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">classes</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Test Accuracy (Overall): </span><span class="si">%2d%%</span><span class="s1"> (</span><span class="si">%2d</span><span class="s1">/</span><span class="si">%2d</span><span class="s1">)&#39;</span> <span class="o">%</span> <span class="p">(</span>
    <span class="mf">100.</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">class_correct</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">class_total</span><span class="p">),</span>
    <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">class_correct</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">class_total</span><span class="p">)))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
 ****************  START TEST ******************* 
Test Loss: 0.030040

Test Accuracy of     0: 95% (57/60)
Test Accuracy of     1: 94% (49/52)

Test Accuracy (Overall): 94% (106/112)
</pre>
</div>
</div>

</div>
</div>

</div>
    

</div>



  </div><a class="u-url" href="/manyFacesML/2023/05/23/CNN_faces.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/manyFacesML/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="https://rohitd3.github.io/manyFacesML/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/manyFacesML/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Fastpages</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li>
  <a rel="me" href="https://github.com/nighthawkcoders" target="_blank" title="github">
    <svg class="svg-icon grey">
      <use xlink:href="/manyFacesML/assets/minima-social-icons.svg#github"></use>
    </svg>
  </a>
</li>
<li>
  <a rel="me" href="https://twitter.com/NighthawkCoding" target="_blank" title="twitter">
    <svg class="svg-icon grey">
      <use xlink:href="/manyFacesML/assets/minima-social-icons.svg#twitter"></use>
    </svg>
  </a>
</li>
<li>
  <a rel="me" href="https://www.youtube.com/channel/UClIKOsDS5dsfzFA3zveDT3Q" target="_blank" title="youtube">
    <svg class="svg-icon grey">
      <use xlink:href="/manyFacesML/assets/minima-social-icons.svg#youtube"></use>
    </svg>
  </a>
</li>
</ul>
</div>

  </div>

</footer>
</body>

</html>
